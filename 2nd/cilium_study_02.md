


---


## 2ì£¼ì°¨ ì‹¤ìŠµ í™˜ê²½ ê°œìš”

![ì‹¤ìŠµ í™˜ê²½ ê°œìš”](image.png)

- **ê¸°ë³¸ ë°°ê¸°ê¸°í¬ ê°€ìƒ ë¨¸ì‹ ** : k8s-ctr, k8s-w1, k8s-w2
- **ì´ˆê¸° í”„ë¡œë¹„ì €ë‹** : kubeadm init, join ì‹¤í–‰
- **Cilium CNI** ì„¤ì¹˜ ìƒíƒœë¡œ ë°°í¬ ì™„ë£Œ

---

## ì‹¤ìŠµ í™˜ê²½ ë°°í¬ íŒŒì¼ ì‘ì„±

- **Vagrantfile** : ê°€ìƒë¨¸ì‹  ì •ì˜, ë¶€íŒ… ì‹œ ì´ˆê¸° í”„ë¡œë¹„ì €ë‹ ì„¤ì •
- **init_cfg.sh** : args ì°¸ê³ í•˜ì—¬ ì„¤ì¹˜
- **k8s-ctr.sh** : kubeadm init, Cilium CNI ì„¤ì¹˜, í¸ë¦¬ì„± ì„¤ì •(k, kc)
- **k8s-w.sh** : kubeadm join

```bash
mkdir cilium-lab && cd cilium-lab
curl -O https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/Vagrantfile
vagrant up
```

---

## ì‹¤ìŠµ í™˜ê²½ ë°°í¬ ë° ì´ˆê¸° ì ê²€

```bash
# /etc/hosts í™•ì¸
cat /etc/hosts

# ê° ì›Œì»¤ ë…¸ë“œ ì ‘ì† í…ŒìŠ¤íŠ¸
sshpass -p 'vagrant' ssh -o StrictHostKeyChecking=no vagrant@k8s-w1 hostname
sshpass -p 'vagrant' ssh -o StrictHostKeyChecking=no vagrant@k8s-w2 hostname

# ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ í™•ì¸
ifconfig | grep -iEA1 'eth[0-9]:'

# í´ëŸ¬ìŠ¤í„° ì •ë³´ í™•ì¸
kubectl cluster-info
kubectl cluster-info dump | grep -m 2 -E "cluster-cidr|service-cluster-ip-range"
kubectl describe cm -n kube-system kubeadm-config
kubectl describe cm -n kube-system kubelet-config

# ë…¸ë“œ ì •ë³´ : ìƒíƒœ, INTERNAL-IP í™•ì¸
kubectl get node -owide

# ë…¸ë“œë³„ kubeadm-flags.env ì •ë³´ í™•ì¸
cat /var/lib/kubelet/kubeadm-flags.env
for i in w1 w2 ; do echo ">> node : k8s-$i <<"; sshpass -p 'vagrant' ssh vagrant@k8s-$i cat /var/lib/kubelet/kubeadm-flags.env ; echo; done

# íŒŒë“œ ì •ë³´ : ìƒíƒœ, íŒŒë“œ IP í™•ì¸
kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'
kubectl get ciliumnode -o json | grep podCIDRs -A2
kubectl get pod -A -owide

# iptables í™•ì¸
iptables-save
iptables -t nat -S
iptables -t filter -S
iptables -t mangle -S
```


---

## k8s-ctr - Cilium ì„¤ì¹˜ ì •ë³´ í™•ì¸

```bash
# cilium ìƒíƒœ í™•ì¸
which cilium
cilium status
cilium config view
kubectl get cm -n kube-system cilium-config -o json | jq

# ìƒì„¸ ìƒíƒœ/ë©”íŠ¸ë¦­
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg config
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg status --verbose
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg metrics list

# ì—”ë“œí¬ì¸íŠ¸ ì •ë³´
kubectl get ciliumendpoints -A

# ëª¨ë‹ˆí„°ë§
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v -v

## ì—”ë“œí¬ì¸íŠ¸ë³„ ëª¨ë‹ˆí„°ë§/ë“œë¡­/HEX
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor --related-to=<id>
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor --type drop
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v -v --hex
```

## Layer 7 ëª¨ë‹ˆí„°ë§

```bash
# Layer 7 íŠ¸ë˜í”½ ëª¨ë‹ˆí„°ë§
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v --type l7
```

---

## 1. Network Observability with Hubble

### Hubble ì†Œê°œ
- **Ciliumì˜ ê´€ì¸¡ ê°€ëŠ¥ì„± í”Œë«í¼**
- **ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ê°€ì‹œì„±** ì œê³µ
- **ì‹¤ì‹œê°„ í”Œë¡œìš° ëª¨ë‹ˆí„°ë§** ê¸°ëŠ¥

### Setting up Hubble Observability

#### ğŸ“‹ ì„¤ì¹˜ ì „ í™•ì¸

```bash
# Cilium ìƒíƒœ í™•ì¸
cilium status
cilium config view | grep -i hubble
kubectl get cm -n kube-system cilium-config -o json | jq

# ê¸°ì¡´ Secret ë° í¬íŠ¸ í™•ì¸
kubectl get secret -n kube-system | grep -iE 'cilium-ca|hubble'
ss -tnlp | grep -iE 'cilium|hubble' | tee before.txt
```

#### ğŸš€ Hubble ì„¤ì¹˜

##### ì„¤ì¹˜ë°©ì•ˆ 1: Helmì„ í†µí•œ ì™„ì „ ì„¤ì¹˜

```bash
# hubble í™œì„±í™”, ë©”íŠ¸ë¦­ ì„¤ì • ë“±ë“±
helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
--set hubble.enabled=true \
--set hubble.relay.enabled=true \
--set hubble.ui.enabled=true \
--set hubble.ui.service.type=NodePort \
--set hubble.ui.service.nodePort=31234 \
--set hubble.export.static.enabled=true \
--set hubble.export.static.filePath=/var/run/cilium/hubble/events.log \
--set prometheus.enabled=true \
--set operator.prometheus.enabled=true \
--set hubble.metrics.enableOpenMetrics=true \
--set hubble.metrics.enabled="{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip\,source_namespace\,source_workload\,destination_ip\,destination_namespace\,destination_workload\,traffic_direction}"

# ì„¤ì¹˜ë°©ì•ˆ 2 : hubble í™œì„±í™”
cilium hubble enable
cilium hubble enable --ui


# This is required for Relay to operate correctly.
cilium status
Hubble Relay:       OK

#
cilium config view | grep -i hubble
kubectl get cm -n kube-system cilium-config -o json | grep -i hubble

#
kubectl get secret -n kube-system | grep -iE 'cilium-ca|hubble'

# # Enabling Hubble requires the TCP port 4244 to be open on all nodes running Cilium.
ss -tnlp | grep -iE 'cilium|hubble' | tee after.txt
vi -d before.txt after.txt
for i in w1 w2 ; do echo ">> node : k8s-$i <<"; sshpass -p 'vagrant' ssh vagrant@k8s-$i sudo ss -tnlp |grep 4244 ; echo; done

#
kubectl get pod -n kube-system -l k8s-app=hubble-relay
kc describe pod -n kube-system -l k8s-app=hubble-relay

kc get svc,ep -n kube-system hubble-relay
...
NAME                     ENDPOINTS           AGE
endpoints/hubble-relay   172.20.1.202:4245   7m54s


# hubble-relay ëŠ” hubble-peer ì˜ ì„œë¹„ìŠ¤(ClusterIP :443)ì„ í†µí•´ ëª¨ë“  ë…¸ë“œì˜ :4244ì— ìš”ì²­ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
kubectl get cm -n kube-system
kubectl describe cm -n kube-system hubble-relay-config
...
cluster-name: default
peer-service: "hubble-peer.kube-system.svc.cluster.local.:443"
listen-address: :4245
...

#
kubectl get svc,ep -n kube-system hubble-peer
NAME                  TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE
service/hubble-peer   ClusterIP   10.96.145.0   <none>        443/TCP   5h55m

NAME                    ENDPOINTS                                                     AGE
endpoints/hubble-peer   192.168.10.100:4244,192.168.10.101:4244,192.168.10.102:4244   5h55m

#
kc describe pod -n kube-system -l k8s-app=hubble-ui
...
Containers:
frontend:
...
backend:
...

kc describe cm -n kube-system hubble-ui-nginx
...

#
kubectl get svc,ep -n kube-system hubble-ui
NAME                TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE
service/hubble-ui   NodePort   10.96.66.67   <none>        80:31234/TCP   17m

NAME                  ENDPOINTS          AGE
endpoints/hubble-ui   172.20.2.70:8081   17m

# hubble ui ì›¹ ì ‘ì† ì£¼ì†Œ í™•ì¸
NODEIP=$(ip -4 addr show eth1 | grep -oP '(?<=inet\s)\d+(\.\d+){3}')
echo -e "http://$NODEIP:31234"
```

- Hubble Client ì„¤ì¹˜
- - **Validate Hubble API Access**
    - In order to **access** the **Hubble API**, create a port forward to the Hubble service from **your local machine.**
    - This will allow you to connect the **Hubble client** to the local portÂ `4245`Â and access the **Hubble Relay service** in your Kubernetes cluster.
    - For more information on this method, seeÂ [Use Port Forwarding to Access Application in a Cluster](https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/).
```
  #
  cilium hubble port-forward&
  Hubble Relay is available at 127.0.0.1:4245
  
  ss -tnlp | grep 4245
  
  # Now you can validate that you can access the Hubble API via the installed CLI
  hubble status
  Healthcheck (via localhost:4245): Ok
  Current/Max Flows: 12,285/12,285 (100.00%)
  Flows/s: 41.20
  
  # hubble (api) server ê¸°ë³¸ ì ‘ì† ì£¼ì†Œ í™•ì¸
  hubble config view 
  ...
  port-forward-port: "4245"
  server: localhost:4245
  ...
  
  # (ì˜µì…˜) í˜„ì¬ k8s-ctr ê°€ìƒë¨¸ì‹ ì´ ì•„ë‹Œ, ìì‹ ì˜ PCì— kubeconfig ì„¤ì • í›„ ì•„ë˜ --server ì˜µì…˜ì„ í†µí•´ hubble api server ì‚¬ìš©í•´ë³´ì!
  hubble help status | grep 'server string'
        --server string                 Address of a Hubble server. Ignored when --input-file or --port-forward is provided. (default "localhost:4245")
  
  # You can also query the flow API and look for flows
  kubectl get ciliumendpoints.cilium.io -n kube-system # SECURITY IDENTITY
  hubble observe
  hubble observe -h
  hubble observe -f
```
- Cilium Agent ë‹¨ì¶•í‚¤ ì§€ì •
```
[- Cilium Agent ë‹¨ì¶•í‚¤ ì§€ì •ã„¹ã…‡ã„´ã…ã„¹ã…‡ã„´ã…ã„¹ã…‡ã„´ã…ã„¹](<# cilium íŒŒë“œ ì´ë¦„
export CILIUMPOD0=$(kubectl get -l k8s-app=cilium pods -n kube-system --field-selector spec.nodeName=k8s-ctr -o jsonpath='{.items[0].metadata.name}')
export CILIUMPOD1=$(kubectl get -l k8s-app=cilium pods -n kube-system --field-selector spec.nodeName=k8s-w1  -o jsonpath='{.items[0].metadata.name}')
export CILIUMPOD2=$(kubectl get -l k8s-app=cilium pods -n kube-system --field-selector spec.nodeName=k8s-w2  -o jsonpath='{.items[0].metadata.name}')
echo $CILIUMPOD0 $CILIUMPOD1 $CILIUMPOD2

# ë‹¨ì¶•í‚¤(alias) ì§€ì •
alias c0="kubectl exec -it $CILIUMPOD0 -n kube-system -c cilium-agent -- cilium"
alias c1="kubectl exec -it $CILIUMPOD1 -n kube-system -c cilium-agent -- cilium"
alias c2="kubectl exec -it $CILIUMPOD2 -n kube-system -c cilium-agent -- cilium"

alias c0bpf="kubectl exec -it $CILIUMPOD0 -n kube-system -c cilium-agent -- bpftool"
alias c1bpf="kubectl exec -it $CILIUMPOD1 -n kube-system -c cilium-agent -- bpftool"
alias c2bpf="kubectl exec -it $CILIUMPOD2 -n kube-system -c cilium-agent -- bpftool"


# endpoint
c0 endpoint list
c0 endpoint list -o json
c1 endpoint list
c2 endpoint list

c1 endpoint get %3Cid%3E
c1 endpoint log <id>

## Enable debugging output on the cilium-dbg monitor for this endpoint
c1 endpoint config <id> Debug=true


# monitor
c1 monitor
c1 monitor -v
c1 monitor -v -v

## Filter for only the events related to endpoint
c1 monitor --related-to=<id>

## Show notifications only for dropped packet events
c1 monitor --type drop

## Donâ€™t dissect packet payload, display payload in hex information
c1 monitor -v -v --hex

## Layer7
c1 monitor -v --type l7


# Manage IP addresses and associated information - IP List
c0 ip list

# IDENTITY :  1(host), 2(world), 4(health), 6(remote), íŒŒë“œë§ˆë‹¤ ê°œë³„ ID
c0 ip list -n

# Retrieve information about an identity
c0 identity list

# ì—”ë“œí¬ì¸íŠ¸ ê¸°ì¤€ ID
c0 identity list --endpoints

# ì—”ë“œí¬ì¸íŠ¸ ì„¤ì • í™•ì¸ ë° ë³€ê²½
c0 endpoint config <ì—”íŠ¸í¬ì¸íŠ¸ID>

# ì—”ë“œí¬ì¸íŠ¸ ìƒì„¸ ì •ë³´ í™•ì¸
c0 endpoint get <ì—”íŠ¸í¬ì¸íŠ¸ID>

# ì—”ë“œí¬ì¸íŠ¸ ë¡œê·¸ í™•ì¸
c0 endpoint log <ì—”íŠ¸í¬ì¸íŠ¸ID>

# Show bpf filesystem mount details
c0 bpf fs show

# bfp ë§ˆìš´íŠ¸ í´ë” í™•ì¸
tree /sys/fs/bpf


# Get list of loadbalancer services
c0 service list
c1 service list
c2 service list

## Or you can get the loadbalancer information using bpf list
c0 bpf lb list
c1 bpf lb list
c2 bpf lb list

## List reverse NAT entries
c1 bpf lb list --revnat
c2 bpf lb list --revnat


# List connection tracking entries
c0 bpf ct list global
c1 bpf ct list global
c2 bpf ct list global

# Flush connection tracking entries
c0 bpf ct flush
c1 bpf ct flush
c2 bpf ct flush


# List all NAT mapping entries
c0 bpf nat list
c1 bpf nat list
c2 bpf nat list

# Flush all NAT mapping entries
c0 bpf nat flush
c1 bpf nat flush
c2 bpf nat flush

# Manage the IPCache mappings for IP/CIDR <-> Identity
c0 bpf ipcache list# Display cgroup metadata maintained by Cilium
c0 cgroups list
c1 cgroups list
c2 cgroups list


# List all open BPF maps
c0 map list
c1 map list --verbose
c2 map list --verbose

c1 map events cilium_lb4_services_v2
c1 map events cilium_lb4_reverse_nat
c1 map events cilium_lxc
c1 map events cilium_ipcache


# List all metrics
c1 metrics list


# List contents of a policy BPF map : Dump all policy maps
c0 bpf policy get --all
c1 bpf policy get --all -n
c2 bpf policy get --all -n


# Dump StateDB contents as JSON
c0 statedb dump


#
c0 shell -- db/show devices
c1 shell -- db/show devices
c2 shell -- db/show devices>)
```

- Getting Started with the Star Wars Demo & Hubble/UI
  - Deploy the Demo Application
![[Pasted image 20250725164406.png]]
- ìŠ¤íƒ€ì›Œì¦ˆì—ì„œ ì˜ê°ì„ ë°›ì€ ì˜ˆì œì—ì„œëŠ” ë°ìŠ¤ìŠ¤íƒ€, íƒ€ì´íŒŒì´í„°, ì—‘ìŠ¤ìœ™ì˜ ì„¸ ê°€ì§€ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ìˆìŠµë‹ˆë‹¤.
- ë°ìŠ¤ìŠ¤íƒ€ëŠ” í¬íŠ¸ 80ì—ì„œ HTTP ì›¹ì„œë¹„ìŠ¤ë¥¼ ì‹¤í–‰í•˜ë©°, ì´ ì„œë¹„ìŠ¤ëŠ” ë‘ ê°œì˜ í¬ë“œ ë³µì œë³¸ì— ê±¸ì³ ë°ìŠ¤ìŠ¤íƒ€ì— ëŒ€í•œ ìš”ì²­ì„ ë¡œë“œ ë°¸ëŸ°ì‹±í•˜ëŠ” Kubernetes ì„œë¹„ìŠ¤ë¡œ ë…¸ì¶œë©ë‹ˆë‹¤.
- ë°ìŠ¤ìŠ¤íƒ€ ì„œë¹„ìŠ¤ëŠ” ì œêµ­ì˜ ìš°ì£¼ì„ ì— ì°©ë¥™ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ì—¬ ì°©ë¥™ í¬íŠ¸ë¥¼ ìš”ì²­í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
- íƒ€ì´íŒŒì´í„° í¬ë“œëŠ” ì¼ë°˜ì ì¸ ì œêµ­ ì„ ë°•ì˜ ì°©ë¥™ ìš”ì²­ í´ë¼ì´ì–¸íŠ¸ ì„œë¹„ìŠ¤ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì—‘ìŠ¤ìœ™ì€ ë™ë§¹ ì„ ë°•ì˜ ìœ ì‚¬í•œ ì„œë¹„ìŠ¤ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
- ë°ìŠ¤ìŠ¤íƒ€ ì°©ë¥™ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì ‘ê·¼ ì œì–´ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ ë³´ì•ˆ ì •ì±…ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆë„ë¡ ì¡´ì¬í•©ë‹ˆë‹¤.
```
#
kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/http-sw-app.yaml
service/deathstar created
deployment.apps/deathstar created
pod/tiefighter created
pod/xwing created

# íŒŒë“œ ë¼ë²¨ labels í™•ì¸
kubectl get pod --show-labels
NAME                        READY   STATUS    RESTARTS   AGE   LABELS
deathstar-8c4c77fb7-9klws   1/1     Running   0          29s   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=8c4c77fb7
deathstar-8c4c77fb7-kkwds   1/1     Running   0          29s   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=8c4c77fb7
tiefighter                  1/1     Running   0          29s   app.kubernetes.io/name=tiefighter,class=tiefighter,org=empire
xwing                       1/1     Running   0          29s   app.kubernetes.io/name=xwing,class=xwing,org=alliance

kubectl get deploy,svc,ep deathstar
NAME                        READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deathstar   2/2     2            2           114s

NAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/deathstar   ClusterIP   10.96.154.223   <none>        80/TCP    114s

NAME                  ENDPOINTS                      AGE
endpoints/deathstar   172.20.1.34:80,172.20.2.1:80   114s

#
kubectl get ciliumendpoints.cilium.io -A
kubectl get ciliumidentities.cilium.io

# in a multi-node installation, only the ones running on the same node will be listed
kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- cilium endpoint list
c0 endpoint list
c1 endpoint list
c2 endpoint list # í˜„ì¬ ingress/egress ì— ì •ì±…(Policy) ì—†ìŒ! , Labels ì •ë³´ í™•ì¸
ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])
...
1579       Disabled           Disabled          318        k8s:app.kubernetes.io/name=deathstar                                                172.20.2.1    ready   
                                                           k8s:class=deathstar                                                                                       
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default                                    
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                  
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                                           
                                                           k8s:io.kubernetes.pod.namespace=default                                                                   
                                                           k8s:org=empire   
```
- **Check Current Access**
    - ë°ìŠ¤ìŠ¤íƒ€ ì„œë¹„ìŠ¤ì˜ ê´€ì ì—ì„œ ë³´ë©´, org= empire ë¼ë²¨ì´ ë¶€ì°©ëœ ì„ ë°•ë§Œ ì—°ê²°í•˜ì—¬ ì°©ë¥™ì„ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ìš°ë¦¬ëŠ” ê·œì¹™ì„ ì‹œí–‰í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— Xwingê³¼ íƒ€ì´íŒŒì´í„° ëª¨ë‘ ì°©ë¥™ì„ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ì•„ë˜ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì„¸ìš”.
```
# ì•„ë˜ ì¶œë ¥ì—ì„œ xwing ì™€ tiefighter ì˜ IDENTITY ë©”ëª¨
c1 endpoint list | grep -iE 'xwing|tiefighter|deathstar'
c2 endpoint list | grep -iE 'xwing|tiefighter|deathstar'
XWINGID=17141
TIEFIGHTERID=56716
DEATHSTARID=8113

# ëª¨ë‹ˆí„°ë§ ì¤€ë¹„ : í„°ë¯¸ë„ 3ê°œ, ë‹¨ì¶•í‚¤ ì„¤ì •
## ê°ê° monitor í™•ì¸
c0 monitor -v -v
c1 monitor -v -v
c2 monitor -v -v

# ëª¨ë‹ˆí„°ë§ ì¤€ë¹„ : í„°ë¯¸ë„ 1ê°œ
hubble observe -f

XWINGID=50633
TIEFIGHTERID=19274
DEATHSTARID=318

hubble observe -f --from-identity $XWINGID
hubble observe -f --protocol udp --from-identity $XWINGID
hubble observe -f --protocol tcp --from-identity $XWINGID

hubble observe -f --protocol tcp --from-identity $DEATHSTARID


# í˜¸ì¶œ ì‹œë„ 1
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
while true; do kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing ; sleep 5 ; done



# í˜¸ì¶œ ì‹œë„ 2
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
while true; do kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing ; sleep 5 ; done

## ëª¨ë‹ˆí„°ë§
hubble observe -f --protocol tcp --from-identity $TIEFIGHTERID
hubble observe -f --protocol tcp --from-identity $DEATHSTARID

```
- Apply an L3/L4 Policy
![[Pasted image 20250725171932.png]]
- Ciliumì„ ì‚¬ìš©í•  ë•Œ ë³´ì•ˆ ì •ì±…ì„ ì •ì˜í•  ë•Œ ì—”ë“œí¬ì¸íŠ¸ IP ì£¼ì†ŒëŠ” ì¤‘ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  **í¬ë“œì— í• ë‹¹ëœ ë ˆì´ë¸”**ì„ ì‚¬ìš©í•˜ì—¬ **ë³´ì•ˆ ì •ì±…ì„ ì •ì˜**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì •ì±…ì€ í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜ ì‹¤í–‰ ì¤‘ì¸ ìœ„ì¹˜ì— ê´€ê³„ì—†ì´ ë ˆì´ë¸”ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜¬ë°”ë¥¸ í¬ë“œì— ì ìš©ë©ë‹ˆë‹¤.
- **ë°ìŠ¤ìŠ¤íƒ€ ì°©ë¥™ ìš”ì²­**ì„ ë¼ë²¨ì´ ìˆëŠ” ì„ ë°•(org=empire)ìœ¼ë¡œë§Œ **ì œí•œ**í•˜ëŠ” **ê¸°ë³¸ ì •ì±…**ë¶€í„° ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ org=empire ë¼ë²¨ì´ ì—†ëŠ” ì„ ë°•ì€ ë°ìŠ¤ìŠ¤íƒ€ ì„œë¹„ìŠ¤ì™€ ì—°ê²°ì¡°ì°¨ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ ì •ì±…ì€ IP í”„ë¡œí† ì½œ(ë„¤íŠ¸ì›Œí¬ ê³„ì¸µ 3)ê³¼ TCP í”„ë¡œí† ì½œ(ë„¤íŠ¸ì›Œí¬ ê³„ì¸µ 4)ì—ë§Œ ì ìš©ë˜ëŠ” ê°„ë‹¨í•œ ì •ì±…ì´ë¯€ë¡œ í”íˆ **L3/L4 ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ ì •ì±…**ì´ë¼ê³  í•©ë‹ˆë‹¤.
- ì°¸ê³ : ì‹¤ë¦¬ì›€ì€ **ìƒíƒœë³„ ì—°ê²° ì¶”ì **ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ëŠ” ì •ì±…ì´ í”„ë¡ íŠ¸ì—”ë“œê°€ ë°±ì—”ë“œì— ë„ë‹¬í•  ìˆ˜ ìˆë„ë¡ í—ˆìš©í•˜ë©´, ë™ì¼í•œ TCP/UDP ì—°ê²° ë‚´ì—ì„œ ë°±ì—”ë“œ ì‘ë‹µì˜ ì¼ë¶€ì¸ ëª¨ë“  **í•„ìˆ˜ ì‘ë‹µ íŒ¨í‚·ì´ ìë™**ìœ¼ë¡œ í”„ë¡ íŠ¸ì—”ë“œì— ë„ë‹¬í•˜ë„ë¡ **í—ˆìš©**í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. _**â†’ ë¦¬í„´ íŒ¨í‚· ìë™ í—ˆìš©!**_
```
# CiliumNetworkPolicy
## CiliumNetworkPolicysëŠ” "endpointSelector"ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŸ ë ˆì´ë¸”ì—ì„œ ì •ì±…ì´ ì ìš©ë˜ëŠ” ì†ŒìŠ¤ì™€ ëª©ì ì§€ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤. 
## ì•„ë˜ ì •ì±…ì€ TCP í¬íŠ¸ 80ì—ì„œ ë ˆì´ë¸”(org=empire)ì´ ìˆëŠ” ëª¨ë“  íŒŸì—ì„œ ë ˆì´ë¸”(org=empire, class=deathstar)ì´ ìˆëŠ” ë°ìŠ¤ìŠ¤íƒ€ íŒŸìœ¼ë¡œ ì „ì†¡ë˜ëŠ” íŠ¸ë˜í”½ì„ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "L3-L4 policy to restrict deathstar access to empire ships only"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - fromEndpoints:
    - matchLabels:
        org: empire
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP

kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/sw_l3_l4_policy.yaml
kubectl get cnp
kubectl get cnp -o json | jq

# ëª¨ë‹ˆí„°ë§
hubble observe -f --type drop

# í˜¸ì¶œ ì‹œë„ 1 
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing --connect-timeout 2


# ëª¨ë‹ˆí„°ë§ 
hubble observe -f --protocol tcp --from-identity $DEATHSTARID

# í˜¸ì¶œ ì‹œë„ 2
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing

```
- Inspecting the Policy
```
# deathstar ì— ingress ì— policy í™œì„±í™” í™•ì¸
c0 endpoint list
c1 endpoint list
c2 endpoint list
ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value]) 
...
1579       Enabled            Disabled          318        k8s:app.kubernetes.io/name=deathstar                                                172.20.2.1    ready   
                                                           k8s:class=deathstar                                                                                       
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default                                    
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                  
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                                           
                                                           k8s:io.kubernetes.pod.namespace=default                                                                   
                                                           k8s:org=empire  
                                                           
#
kc describe cnp rule1

```

- Life of a Packet : L7 ë™ì‘ ì²˜ë¦¬ëŠ” cilium-envoy ë°ëª¬ì…‹ì´ ë‹´ë‹¹
![[Pasted image 20250725172102.png]]
```
#
kubectl get ds -n kube-system
NAME           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
cilium         3         3         3       3            3           kubernetes.io/os=linux   3h38m
cilium-envoy   3         3         3       3            3           kubernetes.io/os=linux   3h38m

kubectl get pod -n kube-system -l k8s-app=cilium-envoy -owide
NAME                 READY   STATUS    RESTARTS   AGE     IP               NODE      NOMINATED NODE   READINESS GATES
cilium-envoy-8427n   1/1     Running   0          3h38m   192.168.10.100   k8s-ctr   <none>           <none>
cilium-envoy-8rzsb   1/1     Running   0          3h36m   192.168.10.101   k8s-w1    <none>           <none>
cilium-envoy-vkqw6   1/1     Running   0          3h35m   192.168.10.102   k8s-w2    <none>           <none>

#
kc describe ds -n kube-system cilium-envoy
...
    Mounts:
      /sys/fs/bpf from bpf-maps (rw)
      /var/run/cilium/envoy/ from envoy-config (ro)
      /var/run/cilium/envoy/artifacts from envoy-artifacts (ro)
      /var/run/cilium/envoy/sockets from envoy-sockets (rw
   ...
   envoy-config:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      cilium-envoy-config
    Optional:  false
...


kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- ss -xnp | grep -i -envoy
u_str ESTAB 0      0                                                  /var/run/cilium/envoy/sockets/xds.sock 32644            * 32610 users:(("cilium-agent",pid=1,fd=64))
u_str ESTAB 0      0                                                /var/run/cilium/envoy/sockets/admin.sock 29697            * 29345
u_str ESTAB 0      0                                                /var/run/cilium/envoy/sockets/admin.sock 29340            * 28672

kc describe cm -n kube-system cilium-envoy-config
...
Data
====
bootstrap-config.json:
----
{"admin":{"address":{"pipe":{"path":"/var/run/cilium/envoy/sockets/admin.sock"}}}...
...

```
- Apply and Test HTTP-aware L7 Policy
![[Pasted image 20250725172147.png]]

- ìœ„ì˜ ê°„ë‹¨í•œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” tiefighter / xwingì—ê²Œ ë°ìŠ¤ìŠ¤íƒ€ APIì— ëŒ€í•œ ì „ì²´ ì•¡ì„¸ìŠ¤ ê¶Œí•œì„ ë¶€ì—¬í•˜ê±°ë‚˜ ì•„ì˜ˆ ì•¡ì„¸ìŠ¤ ê¶Œí•œì„ ë¶€ì—¬í•˜ì§€ ì•ŠëŠ” ê²ƒìœ¼ë¡œ ì¶©ë¶„í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°„ì— ê°€ì¥ ê°•ë ¥í•œ ë³´ì•ˆ(ì¦‰, ìµœì†Œ ê¶Œí•œ ê²©ë¦¬ë¥¼ ê°•ì œí•˜ëŠ” ê²ƒ)ì„ ì œê³µí•˜ê¸° ìœ„í•´ì„œëŠ” ë°ìŠ¤ìŠ¤íƒ€ APIë¥¼ í˜¸ì¶œí•˜ëŠ” ê° ì„œë¹„ìŠ¤ê°€ **í•©ë²•ì ì¸ ìš´ì˜ì— í•„ìš”í•œ HTTP ìš”ì²­ ì„¸íŠ¸ë§Œ ìˆ˜í–‰**í•˜ë„ë¡ ì œí•œí•´ì•¼ í•©ë‹ˆë‹¤.
- ì˜ˆë¥¼ ë“¤ì–´, ë°ìŠ¤ìŠ¤íƒ€ ì„œë¹„ìŠ¤ê°€ ì„ì˜ì˜ ì œêµ­ ì„ ë°•ì´ **í˜¸ì¶œí•´ì„œëŠ” ì•ˆ ë˜ëŠ” ì¼ë¶€ ìœ ì§€ë³´ìˆ˜ APIë¥¼ ë…¸ì¶œ**í•œë‹¤ê³  ê°€ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤.
```
# ëª¨ë‹ˆí„°ë§ >> Layer3/4 ì—ì„œëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœë¥¼ í™•ì¸ í•  ìˆ˜ ì—†ìŒ!
hubble observe -f --protocol tcp --from-identity $DEATHSTARID

# í˜¸ì¶œí•´ì„œëŠ” ì•ˆ ë˜ëŠ” ì¼ë¶€ ìœ ì§€ë³´ìˆ˜ APIë¥¼ ë…¸ì¶œ
kubectl exec tiefighter -- curl -s -XPUT deathstar.default.svc.cluster.local/v1/exhaust-port

```

- L7 Policy with Cilium and Kubernetes
  - Ciliumì€ HTTP ê³„ì¸µ(ì¦‰, L7) ì •ì±…ì„ ì ìš©í•˜ì—¬ íƒ€ì´íŒŒì´í„°ê°€ ë„ë‹¬í•  ìˆ˜ ìˆëŠ” URLì„ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì€ íƒ€ì´íŒŒì´í„°ë¥¼ POST /v1/ìš”ì²­-ëœë”© API í˜¸ì¶œë§Œ ìˆ˜í–‰í•˜ë„ë¡ ì œí•œí•˜ê³  ë‹¤ë¥¸ ëª¨ë“  í˜¸ì¶œ(PUT /v1/ë°°ê¸°í¬íŠ¸ í¬í•¨)ì€ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ì •ì±… íŒŒì¼ì˜ ì˜ˆì…ë‹ˆë‹¤.
```
# ê¸°ì¡´ rule1 ì •ì±…ì„ ì—…ë°ì´íŠ¸ í•´ì„œ ì‚¬ìš©
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "L7 policy to restrict access to specific HTTP call"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - fromEndpoints:
    - matchLabels:
        org: empire
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP
      rules:
        http:
        - method: "POST"
          path: "/v1/request-landing"

# Update the existing rule to apply L7-aware policy to protect deathstar using:
kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/sw_l3_l4_l7_policy.yaml
kubectl get cnp
kc describe cnp
c0 policy get


# ëª¨ë‹ˆí„°ë§ : íŒŒë“œ ì´ë¦„ ì§€ì •
hubble observe -f --pod deathstar --protocol http
Jul 20 01:28:02.184: default/tiefighter:59020 (ID:19274) -> default/deathstar-8c4c77fb7-9klws:80 (ID:318) http-request FORWARDED (HTTP/1.1 POST http://deathstar.default.svc.cluster.local/v1/request-landing)
Jul 20 01:28:02.190: default/tiefighter:59020 (ID:19274) <- default/deathstar-8c4c77fb7-9klws:80 (ID:318) http-response FORWARDED (HTTP/1.1 200 6ms (POST http://deathstar.default.svc.cluster.local/v1/request-landing))

# We can now re-run the same test as above, but we will see a different outcome
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing

```

```
# ëª¨ë‹ˆí„°ë§ : íŒŒë“œ ì´ë¦„ ì§€ì •
hubble observe -f --pod deathstar --verdict DROPPED
Jul 20 01:31:21.248: default/tiefighter:44734 (ID:19274) -> default/deathstar-8c4c77fb7-9klws:80 (ID:318) http-request DROPPED (HTTP/1.1 PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port)

í˜¹ì€
c1 monitor -v --type l7
<- Request http from 3845 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) to 871 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 19274->318, verdict Denied PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port => 0
<- Response http to 3845 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) from 871 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 318->19274, verdict Forwarded PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port => 403
c2 monitor -v --type l7


# We can now re-run the same test as above, but we will see a different outcome
kubectl exec tiefighter -- curl -s -XPUT deathstar.default.svc.cluster.local/v1/exhaust-port
Access denied



# ëª¨ë‹ˆí„°ë§ : íŒŒë“œ ì´ë¦„ ì§€ì •
hubble observe -f --pod xwing

# í˜¸ì¶œ ì‹œë„ : ìœ„ì™€ ì•„ë˜ ì‹¤í–‰ ì¢…ë£Œì˜ ì°¨ì´ì ì„ ì´í•´í•´ë³´ì!
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing --connect-timeout 2

```
- ë‹¤ìŒ ì‹¤ìŠµì„ ìœ„í•´ ë¦¬ì†ŒìŠ¤ ì‚­ì œ
```
# ë‹¤ìŒ ì‹¤ìŠµì„ ìœ„í•´ ë¦¬ì†ŒìŠ¤ ì‚­ì œ
kubectl delete -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/http-sw-app.yaml
kubectl delete cnp rule1

# ì‚­ì œ í™•ì¸
kubectl get cnp

```

- Configuring Hubble exporter : íë¦„ ë¡œê·¸
  - Hubble ExporterëŠ” ë‚˜ì¤‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ **Hubble flows ë¡œê·¸ë¥¼ íŒŒì¼**ì— ì €ì¥í•  ìˆ˜ ìˆëŠ” cilium-agentì˜ ê¸°ëŠ¥ì…ë‹ˆë‹¤.
  - Hubble ExporterëŠ” file rotation, size limits, filters, field masksë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
  - **Hubble Exporter ì„¤ì •** â† Hubble ì„¤ì¹˜ ë•Œ ê°™ì´ ì ìš©ë˜ì–´ ìˆìŒ
```
# ì„¤ì • : ì•„ë˜ ì„¤ì •í•  í•„ìš” ì—†ìŒ
helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
   --set hubble.enabled=true \
   --set hubble.export.static.enabled=true \
   --set hubble.export.static.filePath=/var/run/cilium/hubble/events.log

kubectl -n kube-system rollout status ds/cilium


# í™•ì¸
kubectl get cm -n kube-system cilium-config -o json | grep hubble-export
cilium config view | grep hubble-export
hubble-export-allowlist                           
hubble-export-denylist                            
hubble-export-fieldmask                           
hubble-export-file-max-backups   # number of rotated Hubble export files to keep. (default 5)
hubble-export-file-max-size-mb   # size in MB at which to rotate the Hubble export file. (default 10)
hubble-export-file-path          # file path of target log file. (default /var/run/cilium/hubble/events.log)

# Verify that flow logs are stored in target files
kubectl -n kube-system exec ds/cilium -- tail -f /var/run/cilium/hubble/events.log
kubectl -n kube-system exec ds/cilium -- sh -c 'tail -f /var/run/cilium/hubble/events.log' | jq

```

- Performance tuning
  - Configuration options impacting performance ofÂ **Hubble exporter**Â include:
    - `hubble.export.static.allowList`: specify an **allowlist** as JSON encoded FlowFilters to Hubble exporter.
    - `hubble.export.static.denyList`: specify a **denylist** as JSON encoded FlowFilters to Hubble exporter.
    - `hubble.export.static.fieldMask`: specify a **list** of **fields** to use for field masking in Hubble exporter.
  - Filters & Field mas
    - Field mask is a list of field names from theÂ [flow proto](https://github.com/cilium/cilium/blob/main/api/v1/flow/flow.proto)Â definition.
```
# You can use hubble CLI to generated required filters (see Specifying Raw Flow Filters for more examples).
# For example, to filter flows with verdict DENIED or ERROR, run:
hubble observe --verdict DROPPED --verdict ERROR --print-raw-filters
allowlist:
- '{"verdict":["DROPPED","ERROR"]}'


# To keep all information except pod labels:
hubble-export-fieldmask: time source.identity source.namespace source.pod_name destination.identity destination.namespace destination.pod_name source_service destination_service l4 IP ethernet l7 Type node_name is_reply event_type verdict Summary

# To keep only timestamp, verdict, ports, IP addresses, node name, pod name, and namespace:
hubble-export-fieldmask: time source.namespace source.pod_name destination.namespace destination.pod_name l4 IP node_name is_reply verdict


# ì„¤ì • ë°©ì•ˆ 1 : Then paste the output to hubble-export-allowlist in cilium-config Config Map:
kubectl -n kube-system patch cm cilium-config --patch-file=/dev/stdin <<-EOF
data:
  hubble-export-allowlist: '{"verdict":["DROPPED","ERROR"]}'
  hubble-export-denylist: '{"source_pod":["kube-system/"]},{"destination_pod":["kube-system/"]}'
EOF

# ì„¤ì • ë°©ì•ˆ 2 : helm ì—…ê·¸ë ˆì´ë“œ
helm upgrade cilium cilium/cilium --version 1.17.6 \
   --set hubble.enabled=true \
   --set hubble.export.static.enabled=true \
   --set hubble.export.static.filePath=/var/run/cilium/hubble/events.log \
   --set hubble.export.static.allowList[0]='{"verdict":["DROPPED","ERROR"]}'
   --set hubble.export.static.denyList[0]='{"source_pod":["kube-system/"]}' \
   --set hubble.export.static.denyList[1]='{"destination_pod":["kube-system/"]}' \
   --set "hubble.export.static.fieldMask={time,source.namespace,source.pod_name,destination.namespace,destination.pod_name,l4,IP,node_name,is_reply,verdict,drop_reason_desc}"


# í™•ì¸
cilium config view | grep hubble-export
hubble-export-allowlist                           {"verdict":["DENIED","ERROR"]}
...

kubectl -n kube-system exec ds/cilium -- tail -f /var/run/cilium/hubble/events.log
{"flow":{"time":"2023-08-21T12:12:13.517394084Z","verdict":"DROPPED","IP":{"source":"fe80::64d8:8aff:fe72:fc14","destination":"ff02::2","ipVersion":"IPv6"},"l4":{"ICMPv6":{"type":133}},"source":{},"destination":{},"node_name":"kind-kind/kind-worker","drop_reason_desc":"INVALID_SOURCE_IP"},"node_name":"kind-kind/kind-worker","time":"2023-08-21T12:12:13.517394084Z"}
{"flow":{"time":"2023-08-21T12:12:18.510175415Z","verdict":"DROPPED","IP":{"source":"10.244.1.60","destination":"10.244.1.5","ipVersion":"IPv4"},"l4":{"TCP":{"source_port":44916,"destination_port":80,"flags":{"SYN":true}}},"source":{"namespace":"default","pod_name":"xwing"},"destination":{"namespace":"default","pod_name":"deathstar-7848d6c4d5-th9v2"},"node_name":"kind-kind/kind-worker","drop_reason_desc":"POLICY_DENIED"},"node_name":"kind-kind/kind-worker","time":"2023-08-21T12:12:18.510175415Z"}

```

- **Dynamic exporter configuration - [Docs](https://docs.cilium.io/en/stable/observability/hubble/configuration/export/#dynamic-exporter-configuration)
    - **Standard hubble exporter configuration**ì€ only one set of filters í—ˆìš©í•˜ë©° êµ¬ì„±ì„ ë³€ê²½í•˜ë ¤ë©´ only one set of filtersì´ í•„ìš”í•©ë‹ˆë‹¤.
    - **Dynamic flow logs**ë¥¼ ì‚¬ìš©í•˜ë©´ ì—¬ëŸ¬ í•„í„°ë¥¼ ë™ì‹œì— êµ¬ì„±í•˜ê³  ì¶œë ¥ì„ ë³„ë„ì˜ íŒŒì¼ì— ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë³€ê²½ëœ êµ¬ì„±ì„ ì ìš©í•˜ê¸° ìœ„í•´ **ì‹¤ë¥¨ í¬ë“œ ì¬ì‹œì‘ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµ**ë‹ˆë‹¤.
    - **Dynamic Hubble Exporter**ëŠ” Config Map ì†ì„±ìœ¼ë¡œ í™œì„±í™”ë©ë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œ ê°’ì„ hubble-flowlogs-config-pathë¡œ ì„¤ì •í•  ë•Œê¹Œì§€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.
```
# ì„¤ì • 
helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
   --set hubble.enabled=true \
   --set hubble.export.static.enabled=false \
   --set hubble.export.dynamic.enabled=true

kubectl -n kube-system rollout status ds/cilium


# í¬ë“œë¥¼ ì¬ì‹œì‘í•  í•„ìš” ì—†ì´ íë¦„ ë¡œê·¸ ì„¤ì •ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(êµ¬ì„± ë§µ ì „íŒŒ ì§€ì—°ìœ¼ë¡œ ì¸í•´ ë³€ê²½ ì‚¬í•­ì„ 60ì´ˆ ì´ë‚´ì— ë°˜ì˜í•´ì•¼ í•¨):
helm upgrade cilium cilium/cilium --version 1.17.6 \
   --set hubble.enabled=true \
   --set hubble.export.dynamic.enabled=true \
   --set hubble.export.dynamic.config.content[0].name=system \
   --set hubble.export.dynamic.config.content[0].filePath=/var/run/cilium/hubble/events-system.log \
   --set hubble.export.dynamic.config.content[0].includeFilters[0].source_pod[0]='kube_system/' \
   --set hubble.export.dynamic.config.content[0].includeFilters[1].destination_pod[0]='kube_system/'
```
- Dynamic flow logs can be configured with end property which means that it will automatically stop logging after specified date time. It supports the same field masking and filtering as static hubble exporter.
- For max output file size and backup files dynamic exporter reuses the same settings as static one: `hubble.export.fileMaxSizeMb` and `hubble.export.fileMaxBackups`

#### 2. Running Prometheus & Grafana
- **ìƒ˜í”Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ë° í™•ì¸**
    - ìƒ˜í”Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
```
# ìƒ˜í”Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
EOF


# k8s-ctr ë…¸ë“œì— curl-pod íŒŒë“œ ë°°í¬
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
EOF
```
- í™•ì¸
```
# ë°°í¬ í™•ì¸
kubectl get deploy,svc,ep webpod -owide
kubectl get endpointslices -l app=webpod
kubectl get ciliumendpoints
kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- cilium-dbg endpoint list

# í†µì‹  í™•ì¸
kubectl exec -it curl-pod -- curl webpod | grep Hostname
kubectl exec -it curl-pod -- sh -c 'while true; do curl -s webpod | grep Hostname; sleep 1; done'

```

- **Install Prometheus & Grafana - [Docs](https://docs.cilium.io/en/stable/observability/grafana/)**
    - This is an example deployment that includes Prometheus and Grafana in a **single deployment**. - [Youtube](https://www.youtube.com/watch?v=DdWksYq5Pv4)
        - **Grafana**: A visualization dashboard with **Cilium Dashboard pre-loaded.**
        - **Prometheus**: a time series database and monitoring system.
        - This example deployment of Prometheus and Grafana will **automatically scrape** the **Cilium** and **Hubble metrics**.
```
#
kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes/addons/prometheus/monitoring-example.yaml
configmap/grafana-config created
configmap/grafana-cilium-dashboard created
configmap/grafana-cilium-operator-dashboard created
configmap/grafana-hubble-dashboard created
configmap/grafana-hubble-l7-http-metrics-by-workload created
configmap/prometheus created

#
kubectl get deploy,pod,svc,ep -n cilium-monitoring
kubectl get cm -n cilium-monitoring
NAME                                         DATA   AGE
grafana-cilium-dashboard                     1      113s
grafana-cilium-operator-dashboard            1      113s
grafana-config                               3      113s
grafana-hubble-dashboard                     1      113s
grafana-hubble-l7-http-metrics-by-workload   1      113s
prometheus                                   1      113s

# í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ ì„¤ì •
kc describe cm -n cilium-monitoring prometheus

# ê·¸ë¼íŒŒë‚˜ ì„œë²„ ì„¤ì •
kc describe cm -n cilium-monitoring grafana-config

# ê·¸íŒŒë¼ë‚˜ ëŒ€ì‹œë³´ë“œë“¤ ì£¼ì…ì„ ìœ„í•œ ì„¤ì •
kc describe cm -n cilium-monitoring grafana-cilium-dashboard
kc describe cm -n cilium-monitoring grafana-hubble-dashboard
...
```

- **Deploy Cilium and Hubble with metrics enabled - [Docs](https://docs.cilium.io/en/stable/observability/grafana/#deploy-cilium-and-hubble-with-metrics-enabled)**
    - Cilium, Hubble, and Cilium OperatorëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë©”íŠ¸ë¦­ì„ ë…¸ì¶œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            - ì´ëŸ¬í•œ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ë©”íŠ¸ë¦­ì„ í™œì„±í™”í•˜ë©´ ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†Œê°€ ì‹¤í–‰ ì¤‘ì¸ í´ëŸ¬ìŠ¤í„°ì˜ ëª¨ë“  ë…¸ë“œì— ê°ê° **9962, 9965, 9963** í¬íŠ¸ê°€ ì—´ë¦½ë‹ˆë‹¤.
           -  Cilium, Hubble, and Cilium Operatorì˜ ë©”íŠ¸ë¦­ì€ ëª¨ë‘ ë‹¤ìŒ í—¬ë¦„ ê°’ìœ¼ë¡œ ì„œë¡œ ë…ë¦½ì ìœ¼ë¡œ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤        
        - `prometheus.enabled=true`: Enables metrics forÂ `cilium-agent`.
        - `operator.prometheus.enabled=true`: Enables metrics forÂ `cilium-operator`.
        - `hubble.metrics.enabled`: Enables the provided list of Hubble metrics.
            - For Hubble metrics to work, Hubble itself needs to be enabled withÂ `hubble.enabled=true`.
            - SeeÂ [Hubble exported metrics](https://docs.cilium.io/en/stable/observability/metrics/#hubble-exported-metrics)Â for the list of available Hubble metrics.
        
        _â†’ Refer toÂ [Monitoring & Metrics](https://docs.cilium.io/en/stable/observability/metrics/#metrics)Â for more details about the individual metrics._
    - ë©”íŠ¸ë¦­ ë…¸ì¶œ ì„¤ì • â†’ ì´ë¯¸ ë˜ì–´ ìˆìŒ
```
# ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŒ
helm install cilium cilium/cilium --version 1.17.6 \
   --namespace kube-system \
   --set prometheus.enabled=true \
   --set operator.prometheus.enabled=true \
   --set hubble.enabled=true \
   --set hubble.metrics.enableOpenMetrics=true \
   --set hubble.metrics.enabled="{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip\,source_namespace\,source_workload\,destination_ip\,destination_namespace\,destination_workload\,traffic_direction}"

# í˜¸ìŠ¤íŠ¸ì— í¬íŠ¸ ì •ë³´ í™•ì¸
ss -tnlp | grep -E '9962|9963|9965'
LISTEN 0      4096                *:9963             *:*    users:(("cilium-operator",pid=1488,fd=7)) # cilium-opeator ë©”íŠ¸ë¦­        
LISTEN 0      4096                *:9962             *:*    users:(("cilium-agent",pid=1894,fd=7))    # cilium ë©”íŠ¸ë¦­  
LISTEN 0      4096                *:9965             *:*    users:(("cilium-agent",pid=1894,fd=40))   # hubble ë©”íŠ¸ë¦­

for i in w1 w2 ; do echo ">> node : k8s-$i <<"; sshpass -p 'vagrant' ssh vagrant@k8s-$i sudo ss -tnlp | grep -E '9962|9963|9965' ; echo; done

```

- hostPCì—ì„œ **ì ‘ì†ì„ ìœ„í•œ NodePort ì„¤ì •** ë° â€˜**í”„ë¡œë©”í…Œìš°ìŠ¤ & ê·¸ë¼íŒŒë‚˜**â€™ **ì›¹ ì ‘ì† í™•ì¸ & ê°„ë‹¨ ì¿¼ë¦¬ë¬¸ ì•Œì•„ë³´ê¸°!
  - hostPCì—ì„œ ì ‘ì†ì„ ìœ„í•œ NodePort ì„¤ì •
```
#
kubectl get svc -n cilium-monitoring
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
grafana      ClusterIP   10.96.212.137   <none>        3000/TCP   6m36s
prometheus   ClusterIP   10.96.240.147   <none>        9090/TCP   6m36s

# NodePort ì„¤ì •
kubectl patch svc -n cilium-monitoring prometheus -p '{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}'
kubectl patch svc -n cilium-monitoring grafana -p '{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}'

# í™•ì¸
kubectl get svc -n cilium-monitoring
NAME         TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
grafana      NodePort   10.96.212.137   <none>        3000:30002/TCP   14m
prometheus   NodePort   10.96.240.147   <none>        9090:30001/TCP   14m

# ì ‘ì† ì£¼ì†Œ í™•ì¸
echo "http://192.168.10.100:30001"  # prometheus
echo "http://192.168.10.100:30002"  # grafana

```
