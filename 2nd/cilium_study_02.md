

ì•„ë˜ì™€ ê°™ì´ ì›ë³¸ êµ¬ì„±(Config)ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ì„œ, ê° ì„¹ì…˜ë³„ë¡œ ì„¤ëª…ì„ ì¶”ê°€í•´ ë³´ê¸° ì¢‹ê²Œ ì¬ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

## 2ì£¼ì°¨ ì‹¤ìŠµ í™˜ê²½ ê°œìš”

> 2ì£¼ì°¨ ì‹¤ìŠµì—ì„œëŠ” Vagrant ê¸°ë°˜ì˜ 3ë…¸ë“œ(k8s-ctr, k8s-w1, k8s-w2) í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•˜ê³ , Cilium CNIë¥¼ ì„¤ì¹˜í•œ ë’¤ ì´ˆê¸° ìƒíƒœë¥¼ ì ê²€í•©ë‹ˆë‹¤.

- **ê°€ìƒ ë¨¸ì‹  êµ¬ì„±**  
  - ì»¨íŠ¸ë¡¤ëŸ¬: `k8s-ctr`  
  - ì›Œì»¤ 1: `k8s-w1`  
  - ì›Œì»¤ 2: `k8s-w2`

- **ì´ˆê¸° í”„ë¡œë¹„ì €ë‹**  
  - `kubeadm init` (ì»¨íŠ¸ë¡¤ëŸ¬ ë…¸ë“œ)  
  - `kubeadm join` (ì›Œì»¤ ë…¸ë“œ)

- **Cilium CNI**  
  - CNI í”ŒëŸ¬ê·¸ì¸ìœ¼ë¡œ Cilium ì„¤ì¹˜ ìƒíƒœë¡œ ë°°í¬ ì™„ë£Œ

---

## ì‹¤ìŠµ í™˜ê²½ ë°°í¬ íŒŒì¼ ì‘ì„±

> Vagrantì™€ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì´ìš©í•´ í´ëŸ¬ìŠ¤í„°ë¥¼ ìë™ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹í•©ë‹ˆë‹¤.

- **Vagrantfile**  
  - ê°€ìƒë¨¸ì‹  ì •ì˜  
  - ë¶€íŒ… ì‹œ ì´ˆê¸° í”„ë¡œë¹„ì €ë‹(`init_cfg.sh`, `k8s-ctr.sh`, `k8s-w.sh`) ì„¤ì •

- **init_cfg.sh**  
  - ì¸ì(args)ì— ë”°ë¼ Kubernetes ë° Cilium ì„¤ì¹˜

- **k8s-ctr.sh**  
  - `kubeadm init` ì‹¤í–‰  
  - Cilium CNI ì„¤ì¹˜  
  - í¸ì˜ì„± ì„¤ì •(alias `k`, `kc` ë“±)

- **k8s-w.sh**  
  - `kubeadm join` ì‹¤í–‰

```bash
mkdir cilium-lab && cd cilium-lab
curl -O https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/Vagrantfile
vagrant up


â¸»

ì‹¤ìŠµ í™˜ê²½ ë°°í¬ ë° ì´ˆê¸° ì ê²€

í´ëŸ¬ìŠ¤í„°ê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ ë„¤íŠ¸ì›Œí¬, ë…¸ë“œ, íŒŒë“œ, iptables ìƒíƒœ ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.

# 1. /etc/hosts í™•ì¸
cat /etc/hosts

# 2. ì›Œì»¤ ë…¸ë“œ ì ‘ì† í…ŒìŠ¤íŠ¸
sshpass -p 'vagrant' ssh -o StrictHostKeyChecking=no vagrant@k8s-w1 hostname
sshpass -p 'vagrant' ssh -o StrictHostKeyChecking=no vagrant@k8s-w2 hostname

# 3. ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ í™•ì¸
ifconfig | grep -iEA1 'eth[0-9]:'

# 4. í´ëŸ¬ìŠ¤í„° ì •ë³´ í™•ì¸
kubectl cluster-info
kubectl cluster-info dump | grep -m 2 -E "cluster-cidr|service-cluster-ip-range"
kubectl describe cm -n kube-system kubeadm-config
kubectl describe cm -n kube-system kubelet-config

# 5. ë…¸ë“œ ì •ë³´ ì¡°íšŒ (ìƒíƒœ, INTERNAL-IP)
kubectl get node -o wide

# 6. kubelet ì¸ì í™•ì¸
cat /var/lib/kubelet/kubeadm-flags.env
for i in w1 w2 ; do
  echo ">> node : k8s-$i <<"
  sshpass -p 'vagrant' ssh vagrant@k8s-$i cat /var/lib/kubelet/kubeadm-flags.env
  echo
done

# 7. íŒŒë“œ CIDR ë° IP í™•ì¸
kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'
kubectl get ciliumnode -o json | grep podCIDRs -A2
kubectl get pod -A -o wide

# 8. iptables ì„¤ì • í™•ì¸
iptables-save
iptables -t nat -S
iptables -t filter -S
iptables -t mangle -S


â¸»

k8s-ctr â€“ Cilium ì„¤ì¹˜ ì •ë³´ í™•ì¸

Cilium ë°”ì´ë„ˆë¦¬ ì„¤ì¹˜ ì—¬ë¶€, ì„¤ì •(ConfigMap), ìƒíƒœ, ë©”íŠ¸ë¦­, ì—”ë“œí¬ì¸íŠ¸ ë“±ì„ ìƒì„¸íˆ ì ê²€í•©ë‹ˆë‹¤.

# 1. cilium ë°”ì´ë„ˆë¦¬ ë° ê¸°ë³¸ ìƒíƒœ í™•ì¸
which cilium
cilium status
cilium config view
kubectl get cm -n kube-system cilium-config -o json | jq

# 2. ìƒì„¸ ìƒíƒœ ë° ë©”íŠ¸ë¦­
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg config
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg status --verbose
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg metrics list

# 3. ì—”ë“œí¬ì¸íŠ¸ ì •ë³´
kubectl get ciliumendpoints -A

# 4. íŠ¸ë˜í”½ ëª¨ë‹ˆí„°ë§
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v -v

# 5. ì—”ë“œí¬ì¸íŠ¸ë³„ ìƒì„¸ ëª¨ë‹ˆí„°ë§ ë° ë“œë¡­ í™•ì¸
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor --related-to=<id>
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor --type drop
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v -v --hex


â¸»

Layer 7 ëª¨ë‹ˆí„°ë§

L7(HTTP ë“± ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨) íŠ¸ë˜í”½ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•˜ì—¬ ì •ì±… ì ìš© ê²°ê³¼ë¥¼ ì ê²€í•©ë‹ˆë‹¤.

kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v --type l7

## 1. Network Observability with Hubble

### Hubble ì†Œê°œ
Ciliumì´ ì œê³µí•˜ëŠ” ë„¤íŠ¸ì›Œí¬ ê´€ì¸¡(Observability) í”Œë«í¼ìœ¼ë¡œ,  
- **ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ê°€ì‹œì„±** ì œê³µ  
- **ì‹¤ì‹œê°„ í”Œë¡œìš° ëª¨ë‹ˆí„°ë§** ê¸°ëŠ¥ ì œê³µ  

---

### ğŸ“‹ ì„¤ì¹˜ ì „ í™•ì¸
ì„¤ì¹˜ì— ì•ì„œ ê¸°ì¡´ Cilium ë° Hubble ê´€ë ¨ ë¦¬ì†ŒìŠ¤ì™€ í¬íŠ¸ ìƒíƒœë¥¼ ì ê²€í•©ë‹ˆë‹¤.

```bash
# 1) Cilium ìƒíƒœ ë° ì„¤ì • í™•ì¸
cilium status
cilium config view | grep -i hubble
kubectl get cm -n kube-system cilium-config -o json | jq

# 2) ê¸°ì¡´ Secret í™•ì¸
kubectl get secret -n kube-system | grep -iE 'cilium-ca|hubble'

# 3) í¬íŠ¸(4244 ë“±) ì—´ë¦¼ ì—¬ë¶€ í™•ì¸ (ì„¤ì¹˜ ì „)
ss -tnlp | grep -iE 'cilium|hubble' | tee before.txt


â¸»

ğŸš€ Hubble ì„¤ì¹˜

ì„¤ì¹˜ë°©ì•ˆ 1: Helm ì°¨íŠ¸ë¡œ ì™„ì „ ì„¤ì¹˜

Helmì„ í†µí•´ Hubble, Relay, UI, Prometheus exporter ë“±ì„ í•œ ë²ˆì— êµ¬ì„±í•©ë‹ˆë‹¤.

helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
  --set hubble.enabled=true \
  --set hubble.relay.enabled=true \
  --set hubble.ui.enabled=true \
  --set hubble.ui.service.type=NodePort \
  --set hubble.ui.service.nodePort=31234 \
  --set hubble.export.static.enabled=true \
  --set hubble.export.static.filePath=/var/run/cilium/hubble/events.log \
  --set prometheus.enabled=true \
  --set operator.prometheus.enabled=true \
  --set hubble.metrics.enableOpenMetrics=true \
  --set hubble.metrics.enabled="{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip\,source_namespace\,source_workload\,destination_ip\,destination_namespace\,destination_workload\,traffic_direction}"

ì„¤ì¹˜ë°©ì•ˆ 2: cilium CLIë¡œ ê°„ë‹¨ í™œì„±í™”

Hubbleë§Œ ê°„ë‹¨íˆ í™œì„±í™”í•˜ê±°ë‚˜, UIê¹Œì§€ í¬í•¨í•´ì„œ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# Hubble core í™œì„±í™”
cilium hubble enable

# Hubble UI(ì›¹ ëŒ€ì‹œë³´ë“œ)ê¹Œì§€ í™œì„±í™”
cilium hubble enable --ui


â¸»

âš™ï¸ ì„¤ì¹˜ í›„ ê²€ì¦

ì„¤ì¹˜ê°€ ì™„ë£Œëœ í›„, Relay ìƒíƒœì™€ ConfigMap, Secret, í¬íŠ¸ ì—´ë¦¼ ìƒíƒœ ë“±ì„ ë‹¤ì‹œ í™•ì¸í•©ë‹ˆë‹¤.

# Relay ìƒíƒœ í™•ì¸
cilium status
# â†’ â€œHubble Relay: OKâ€ ë©”ì‹œì§€ í™•ì¸

# Hubble ì„¤ì • ë°˜ì˜ í™•ì¸
cilium config view | grep -i hubble
kubectl get cm -n kube-system cilium-config -o json | grep -i hubble

# Secret í™•ì¸
kubectl get secret -n kube-system | grep -iE 'cilium-ca|hubble'

# í¬íŠ¸(4244) ì—´ë¦¼ ì—¬ë¶€ í™•ì¸ (ì„¤ì¹˜ í›„)
ss -tnlp | grep -iE 'cilium|hubble' | tee after.txt
vi -d before.txt after.txt

# ê° ì›Œì»¤ ë…¸ë“œì—ì„œë„ 4244 í¬íŠ¸ í™•ì¸
for i in w1 w2 ; do
  echo ">> node : k8s-$i <<"
  sshpass -p 'vagrant' ssh vagrant@k8s-$i sudo ss -tnlp | grep 4244
  echo
done


â¸»

ğŸ”— Hubble Relay êµ¬ì„± í™•ì¸

RelayëŠ” ê° ë…¸ë“œì˜ Hubble ë°ì´í„°ë¥¼ ì§‘ê³„í•´ì£¼ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

# Relay Pod í™•ì¸
kubectl get pod -n kube-system -l k8s-app=hubble-relay
kc describe pod -n kube-system -l k8s-app=hubble-relay

# Relay ì„œë¹„ìŠ¤ ë° Endpoint í™•ì¸
kc get svc,ep -n kube-system hubble-relay
# NAME                     ENDPOINTS           AGE
# endpoints/hubble-relay   172.20.1.202:4245   7m54s

# Relay ì„¤ì •(ConfigMap) í™•ì¸
kubectl describe cm -n kube-system hubble-relay-config
# â†’ cluster-name, peer-service, listen-address ë“± í™•ì¸

# ì˜ˆì‹œ: hubble-relay-config ì¼ë¶€
cluster-name: default
peer-service: "hubble-peer.kube-system.svc.cluster.local.:443"
listen-address: :4245


â¸»

ğŸ”— Hubble Peer êµ¬ì„± í™•ì¸

PeerëŠ” ê° ë…¸ë“œì—ì„œ Hubble APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.

# Peer ì„œë¹„ìŠ¤ ë° Endpoint í™•ì¸
kubectl get svc,ep -n kube-system hubble-peer
# NAME                  TYPE        CLUSTER-IP    PORT(S)   AGE
# service/hubble-peer   ClusterIP   10.96.145.0   443/TCP   5h55m

# Endpoint ëª©ë¡ (ë…¸ë“œë³„ 4244 í¬íŠ¸)
# 192.168.10.100:4244,192.168.10.101:4244,192.168.10.102:4244


â¸»

ğŸ–¥ï¸ Hubble UI(Web) êµ¬ì„± í™•ì¸

UIëŠ” NGINXë¥¼ í†µí•´ Relayì— ì—°ê²°ëœ ë°ì´í„°ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.

# UI Pod ë° Container í™•ì¸
kc describe pod -n kube-system -l k8s-app=hubble-ui

# UI NGINX ì„¤ì • í™•ì¸
kc describe cm -n kube-system hubble-ui-nginx

# UI ì„œë¹„ìŠ¤ ë° Endpoint í™•ì¸
kubectl get svc,ep -n kube-system hubble-ui
# NAME                TYPE       CLUSTER-IP    PORT(S)        AGE
# service/hubble-ui   NodePort   10.96.66.67   80:31234/TCP   17m
# endpoints/hubble-ui   172.20.2.70:8081   17m


â¸»

ğŸŒ Hubble UI ì ‘ì† ë°©ë²•
	1.	ê° ë…¸ë“œì˜ eth1 ì¸í„°í˜ì´ìŠ¤ IPë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
	2.	ë¸Œë¼ìš°ì €ì—ì„œ http://<NODE_IP>:31234 ë¡œ ì ‘ì†í•©ë‹ˆë‹¤.

NODEIP=$(ip -4 addr show eth1 | grep -oP '(?<=inet\s)\d+(\.\d+){3}')
echo -e "Hubble UI ì£¼ì†Œ â†’ http://$NODEIP:31234"

## Hubble Client ì„¤ì¹˜ ë° API ì ‘ê·¼ ê²€ì¦

> ë¡œì»¬ ë¨¸ì‹ ì—ì„œ Hubble Relay ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ í¬íŠ¸ í¬ì›Œë”© ë° CLI ì‚¬ìš© ë°©ë²•

```bash
  #
  cilium hubble port-forward&
  Hubble Relay is available at 127.0.0.1:4245
  
  ss -tnlp | grep 4245
  
  # Now you can validate that you can access the Hubble API via the installed CLI
  hubble status
  Healthcheck (via localhost:4245): Ok
  Current/Max Flows: 12,285/12,285 (100.00%)
  Flows/s: 41.20
  
  # hubble (api) server ê¸°ë³¸ ì ‘ì† ì£¼ì†Œ í™•ì¸
  hubble config view 
  ...
  port-forward-port: "4245"
  server: localhost:4245
  ...
  
  # (ì˜µì…˜) í˜„ì¬ k8s-ctr ê°€ìƒë¨¸ì‹ ì´ ì•„ë‹Œ, ìì‹ ì˜ PCì— kubeconfig ì„¤ì • í›„ ì•„ë˜ --server ì˜µì…˜ì„ í†µí•´ hubble api server ì‚¬ìš©í•´ë³´ì!
  hubble help status | grep 'server string'
        --server string                 Address of a Hubble server. Ignored when --input-file or --port-forward is provided. (default "localhost:4245")
  
  # You can also query the flow API and look for flows
  kubectl get ciliumendpoints.cilium.io -n kube-system # SECURITY IDENTITY
  hubble observe
  hubble observe -h
  hubble observe -f


â¸»

Cilium Agent ë‹¨ì¶•í‚¤ ì§€ì •

ê° ë…¸ë“œì˜ Cilium Agent Podì— ë¹ ë¥´ê²Œ ì ‘ì†í•˜ê¸° ìœ„í•œ alias ì„¤ì •

[- Cilium Agent ë‹¨ì¶•í‚¤ ì§€ì •ã„¹ã…‡ã„´ã…ã„¹ã…‡ã„´ã…ã„¹ã…‡ã„´ã…ã„¹](<# cilium íŒŒë“œ ì´ë¦„
export CILIUMPOD0=$(kubectl get -l k8s-app=cilium pods -n kube-system --field-selector spec.nodeName=k8s-ctr -o jsonpath='{.items[0].metadata.name}')
export CILIUMPOD1=$(kubectl get -l k8s-app=cilium pods -n kube-system --field-selector spec.nodeName=k8s-w1  -o jsonpath='{.items[0].metadata.name}')
export CILIUMPOD2=$(kubectl get -l k8s-app=cilium pods -n kube-system --field-selector spec.nodeName=k8s-w2  -o jsonpath='{.items[0].metadata.name}')
echo $CILIUMPOD0 $CILIUMPOD1 $CILIUMPOD2

# ë‹¨ì¶•í‚¤(alias) ì§€ì •
alias c0="kubectl exec -it $CILIUMPOD0 -n kube-system -c cilium-agent -- cilium"
alias c1="kubectl exec -it $CILIUMPOD1 -n kube-system -c cilium-agent -- cilium"
alias c2="kubectl exec -it $CILIUMPOD2 -n kube-system -c cilium-agent -- cilium"

alias c0bpf="kubectl exec -it $CILIUMPOD0 -n kube-system -c cilium-agent -- bpftool"
alias c1bpf="kubectl exec -it $CILIUMPOD1 -n kube-system -c cilium-agent -- bpftool"
alias c2bpf="kubectl exec -it $CILIUMPOD2 -n kube-system -c cilium-agent -- bpftool"


# endpoint
c0 endpoint list
c0 endpoint list -o json
c1 endpoint list
c2 endpoint list

c1 endpoint get %3Cid%3E
c1 endpoint log <id>

## Enable debugging output on the cilium-dbg monitor for this endpoint
c1 endpoint config <id> Debug=true


# monitor
c1 monitor
c1 monitor -v
c1 monitor -v -v

## Filter for only the events related to endpoint
c1 monitor --related-to=<id>

## Show notifications only for dropped packet events
c1 monitor --type drop

## Donâ€™t dissect packet payload, display payload in hex information
c1 monitor -v -v --hex

## Layer7
c1 monitor -v --type l7


# Manage IP addresses and associated information - IP List
c0 ip list

# IDENTITY :  1(host), 2(world), 4(health), 6(remote), íŒŒë“œë§ˆë‹¤ ê°œë³„ ID
c0 ip list -n

# Retrieve information about an identity
c0 identity list

# ì—”ë“œí¬ì¸íŠ¸ ê¸°ì¤€ ID
c0 identity list --endpoints

# ì—”ë“œí¬ì¸íŠ¸ ì„¤ì • í™•ì¸ ë° ë³€ê²½
c0 endpoint config <ì—”íŠ¸í¬ì¸íŠ¸ID>

# ì—”ë“œí¬ì¸íŠ¸ ìƒì„¸ ì •ë³´ í™•ì¸
c0 endpoint get <ì—”íŠ¸í¬ì¸íŠ¸ID>

# ì—”ë“œí¬ì¸íŠ¸ ë¡œê·¸ í™•ì¸
c0 endpoint log <ì—”íŠ¸í¬ì¸íŠ¸ID>

# Show bpf filesystem mount details
c0 bpf fs show

# bfp ë§ˆìš´íŠ¸ í´ë” í™•ì¸
tree /sys/fs/bpf


# Get list of loadbalancer services
c0 service list
c1 service list
c2 service list

## Or you can get the loadbalancer information using bpf list
c0 bpf lb list
c1 bpf lb list
c2 bpf lb list

## List reverse NAT entries
c1 bpf lb list --revnat
c2 bpf lb list --revnat


# List connection tracking entries
c0 bpf ct list global
c1 bpf ct list global
c2 bpf ct list global

# Flush connection tracking entries
c0 bpf ct flush
c1 bpf ct flush
c2 bpf ct flush


# List all NAT mapping entries
c0 bpf nat list
c1 bpf nat list
c2 bpf nat list

# Flush all NAT mapping entries
c0 bpf nat flush
c1 bpf nat flush
c2 bpf nat flush

# Manage the IPCache mappings for IP/CIDR <-> Identity
c0 bpf ipcache list# Display cgroup metadata maintained by Cilium
c0 cgroups list
c1 cgroups list
c2 cgroups list


# List all open BPF maps
c0 map list
c1 map list --verbose
c2 map list --verbose

c1 map events cilium_lb4_services_v2
c1 map events cilium_lb4_reverse_nat
c1 map events cilium_lxc
c1 map events cilium_ipcache


# List all metrics
c1 metrics list


# List contents of a policy BPF map : Dump all policy maps
c0 bpf policy get --all
c1 bpf policy get --all -n
c2 bpf policy get --all -n


# Dump StateDB contents as JSON
c0 statedb dump


#
c0 shell -- db/show devices
c1 shell -- db/show devices
c2 shell -- db/show devices>)

## Getting Started with the Star Wars Demo & Hubble/UI

> ìŠ¤íƒ€ì›Œì¦ˆ ë°ëª¨ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë°°í¬í•˜ê³ , Cilium/Hubble UIë¡œ ë„¤íŠ¸ì›Œí¬ í”Œë¡œìš°ë¥¼ ê´€ì°°í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.

---

### 1. ë°ëª¨ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬

ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‹¤í–‰í•˜ì—¬ Deathstar, Tiefighter, Xwing ë¦¬ì†ŒìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  
(ë³€ê²½ ì—†ì´ ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€)

```bash
#
kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/http-sw-app.yaml
service/deathstar created
deployment.apps/deathstar created
pod/tiefighter created
pod/xwing created

# íŒŒë“œ ë¼ë²¨ labels í™•ì¸
kubectl get pod --show-labels
NAME                        READY   STATUS    RESTARTS   AGE   LABELS
deathstar-8c4c77fb7-9klws   1/1     Running   0          29s   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=8c4c77fb7
deathstar-8c4c77fb7-kkwds   1/1     Running   0          29s   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=8c4c77fb7
tiefighter                  1/1     Running   0          29s   app.kubernetes.io/name=tiefighter,class=tiefighter,org=empire
xwing                       1/1     Running   0          29s   app.kubernetes.io/name=xwing,class=xwing,org=alliance

kubectl get deploy,svc,ep deathstar
NAME                        READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deathstar   2/2     2            2           114s

NAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/deathstar   ClusterIP   10.96.154.223   <none>        80/TCP    114s

NAME                  ENDPOINTS                      AGE
endpoints/deathstar   172.20.1.34:80,172.20.2.1:80   114s

ìœ„ ëª…ë ¹ì„ í†µí•´ Deathstar ì„œë¹„ìŠ¤ê°€ 2ê°œì˜ íŒŒë“œë¡œ ë¡œë“œë°¸ëŸ°ì‹±ë˜ë©°, Tiefighter/Xwing íŒŒë“œê°€ ìƒì„±ë©ë‹ˆë‹¤.

â¸»

2. Cilium Endpoint & Identity í™•ì¸

ì•„ë˜ ëª…ë ¹ì–´ë¡œ Cilium ë¦¬ì†ŒìŠ¤ë¥¼ ì¡°íšŒí•˜ì—¬, í˜„ì¬ Policyê°€ ë¹„í™œì„±(Disabled) ìƒíƒœì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ì „ì²´ Endpoint, Identity ë¦¬ì†ŒìŠ¤ ì¡°íšŒ
kubectl get ciliumendpoints.cilium.io -A
kubectl get ciliumidentities.cilium.io

# ë…¸ë“œë³„ Cilium Agentì—ì„œ Endpoint ëª©ë¡ ì¡°íšŒ
kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- cilium endpoint list

# aliasë¥¼ ì‚¬ìš©í•œ ë‹¨ì¶• ì¡°íšŒ (c0, c1, c2)
c0 endpoint list
c1 endpoint list
c2 endpoint list # í˜„ì¬ ingress/egress ì— ì •ì±…(Policy) ì—†ìŒ! , Labels ì •ë³´ í™•ì¸

# Endpoint ìƒì„¸ ì •ë³´ ë° ë¼ë²¨
ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])
...
1579       Disabled           Disabled          318        k8s:app.kubernetes.io/name=deathstar                                                172.20.2.1    ready   
                                                           k8s:class=deathstar                                                                                       
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default                                    
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                  
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                                           
                                                           k8s:io.kubernetes.pod.namespace=default                                                                   
                                                           k8s:org=empire   

Policy(ingress/egress)ê°€ Disabled ìƒíƒœì´ë¯€ë¡œ, ì´í›„ ë³´ì•ˆ ì •ì±… ì ìš© ì „í›„ë¥¼ ë¹„êµ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Check Current Access

> í˜„ì¬ í´ëŸ¬ìŠ¤í„°ì—ì„œ org=empire ë¼ë²¨ì´ ì—†ëŠ” `xwing`, `tiefighter`ë„ Deathstar ì„œë¹„ìŠ¤ì— ìš”ì²­í•  ìˆ˜ ìˆëŠ” ìƒíƒœì…ë‹ˆë‹¤.  
> ì•„ë˜ ëª…ë ¹ìœ¼ë¡œ ê° Podì˜ Identity IDë¥¼ í™•ì¸í•˜ê³ , ëª¨ë‹ˆí„°ë§ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.

```bash
# Identity ID í™•ì¸ (c1, c2 ë…¸ë“œ)
c1 endpoint list | grep -iE 'xwing|tiefighter|deathstar'
c2 endpoint list | grep -iE 'xwing|tiefighter|deathstar'
XWINGID=17141
TIEFIGHTERID=56716
DEATHSTARID=8113

# ëª¨ë‹ˆí„°ë§ ì¤€ë¹„: í„°ë¯¸ë„ 3ê°œì—ì„œ ê°ê° Cilium Agent ëª¨ë‹ˆí„°ë§
c0 monitor -v -v
c1 monitor -v -v
c2 monitor -v -v

# ëª¨ë‹ˆí„°ë§ ì¤€ë¹„: í„°ë¯¸ë„ 1ê°œì—ì„œ Hubble í”Œë¡œìš° ê´€ì°°
hubble observe -f

# Hubble í”Œë¡œìš° í•„í„°ë§ ì˜ˆì‹œ
hubble observe -f --from-identity $XWINGID
hubble observe -f --protocol udp --from-identity $XWINGID
hubble observe -f --protocol tcp --from-identity $XWINGID
hubble observe -f --protocol tcp --from-identity $DEATHSTARID

ì´ì œ xwingê³¼ tiefighterì—ì„œ Deathstar Landing APIë¥¼ í˜¸ì¶œí•˜ì—¬, ì‹¤ì œ íŠ¸ë˜í”½ì´ í—ˆìš©ë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# í˜¸ì¶œ ì‹œë„ 1: Xwingì—ì„œ ìš”ì²­
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
while true; do
  kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
  sleep 5
done

# í˜¸ì¶œ ì‹œë„ 2: Tiefighterì—ì„œ ìš”ì²­
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
while true; do
  kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
  sleep 5
done

# ëª¨ë‹ˆí„°ë§: TCP í”Œë¡œìš° í™•ì¸
hubble observe -f --protocol tcp --from-identity $TIEFIGHTERID
hubble observe -f --protocol tcp --from-identity $DEATHSTARID


â¸»

Apply an L3/L4 Policy

ì´ì œ org=empire ë¼ë²¨ì´ ìˆëŠ” ì„ ë°•ë§Œ Deathstar ì„œë¹„ìŠ¤ì— ì ‘ê·¼í•˜ë„ë¡ L3/L4 ì •ì±…ì„ ì ìš©í•©ë‹ˆë‹¤.
CiliumNetworkPolicyëŠ” ë ˆì´ë¸”ì„ ê¸°ë°˜ìœ¼ë¡œ ì†ŒìŠ¤/ëª©ì ì§€ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.

# CiliumNetworkPolicy: empire ì¡°ì§ì˜ Deathstar ì ‘ê·¼ë§Œ í—ˆìš©
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "L3-L4 policy to restrict deathstar access to empire ships only"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - fromEndpoints:
    - matchLabels:
        org: empire
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP

# ì •ì±… ì ìš© ë° í™•ì¸
kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/sw_l3_l4_policy.yaml
kubectl get cnp
kubectl get cnp -o json | jq

# ë“œë¡­ëœ íŒ¨í‚· ëª¨ë‹ˆí„°ë§
hubble observe -f --type drop

ì •ì±… ì ìš© í›„, ë‹¤ì‹œ xwing(org=alliance)ì—ì„œ ìš”ì²­ì„ ì‹œë„í•˜ë©´ ì—°ê²°ì¡°ì°¨ ë˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.

# í˜¸ì¶œ ì‹œë„ 1: Xwingì—ì„œ ìš”ì²­ (íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ì—°ê²° ì‹¤íŒ¨)
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing --connect-timeout 2

# ëª¨ë‹ˆí„°ë§: Deathstar â†’ Xwing ê°„ TCP íŠ¸ë˜í”½
hubble observe -f --protocol tcp --from-identity $DEATHSTARID

# í˜¸ì¶œ ì‹œë„ 2: Tiefighterì—ì„œ ìš”ì²­ (íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ì—°ê²° ì‹¤íŒ¨)
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing

- ìœ„ ê²°ê³¼ë¥¼ í†µí•´ org=empire ë¼ë²¨ì„ ê°€ì§€ì§€ ì•Šì€ Podì˜ Deathstar ì ‘ê·¼ì´ ì°¨ë‹¨ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
## Inspecting the Policy

> CiliumNetworkPolicyê°€ `deathstar` íŒŒë“œì˜ ingressì— ì ìš©ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

```bash
# deathstar ì— ingress ì— policy í™œì„±í™” í™•ì¸
c0 endpoint list
c1 endpoint list
c2 endpoint list
ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value]) 
...
1579       Enabled            Disabled          318        k8s:app.kubernetes.io/name=deathstar                                                172.20.2.1    ready   
                                                           k8s:class=deathstar                                                                                       
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default                                    
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                  
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                                           
                                                           k8s:io.kubernetes.pod.namespace=default                                                                   
                                                           k8s:org=empire  
                                                           
#
kc describe cnp rule1

ìœ„ ì¶œë ¥ì—ì„œ Enabledë¡œ í‘œì‹œëœ ê²ƒì„ í†µí•´ deathstar íŒŒë“œì˜ ingressì— ì •ì±…ì´ ì •ìƒ ì ìš©ë˜ì—ˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
kc describe cnp rule1 ëª…ë ¹ìœ¼ë¡œ ì •ì±…ì˜ endpointSelector, ingress.fromEndpoints, toPorts ë“±ì˜ ìƒì„¸ ì„¤ì •ì„ ê²€í† í•˜ì„¸ìš”.

â¸»

Life of a Packet : L7 ë™ì‘ ì²˜ë¦¬ëŠ” cilium-envoy ë°ëª¬ì…‹ì´ ë‹´ë‹¹

Layer 7(HTTP/gRPC) ì •ì±…ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ Envoy í”„ë¡ì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì•„ë˜ ëª…ë ¹ì–´ë¡œ ë°ëª¬ì…‹ê³¼ ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

#
kubectl get ds -n kube-system
NAME           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
cilium         3         3         3       3            3           kubernetes.io/os=linux   3h38m
cilium-envoy   3         3         3       3            3           kubernetes.io/os=linux   3h38m

kubectl get pod -n kube-system -l k8s-app=cilium-envoy -owide
NAME                 READY   STATUS    RESTARTS   AGE     IP               NODE      NOMINATED NODE   READINESS GATES
cilium-envoy-8427n   1/1     Running   0          3h38m   192.168.10.100   k8s-ctr   <none>           <none>
cilium-envoy-8rzsb   1/1     Running   0          3h36m   192.168.10.101   k8s-w1    <none>           <none>
cilium-envoy-vkqw6   1/1     Running   0          3h35m   192.168.10.102   k8s-w2    <none>           <none>

#
kc describe ds -n kube-system cilium-envoy
...
    Mounts:
      /sys/fs/bpf from bpf-maps (rw)
      /var/run/cilium/envoy/ from envoy-config (ro)
      /var/run/cilium/envoy/artifacts from envoy-artifacts (ro)
      /var/run/cilium/envoy/sockets from envoy-sockets (rw
   ...
   envoy-config:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      cilium-envoy-config
    Optional:  false
...

DaemonSetì˜ ë³¼ë¥¨ ë§ˆìš´íŠ¸ ì •ë³´ë¥¼ í†µí•´ Envoyê°€ BPF ë§µê³¼ ì„¤ì • íŒŒì¼, ì†Œì¼“ì„ ì˜¬ë°”ë¥´ê²Œ ë§ˆìš´íŠ¸í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- ss -xnp | grep -i -envoy
u_str ESTAB 0      0                                                  /var/run/cilium/envoy/sockets/xds.sock 32644            * 32610 users:(("cilium-agent",pid=1,fd=64))
u_str ESTAB 0      0                                                /var/run/cilium/envoy/sockets/admin.sock 29697            * 29345
u_str ESTAB 0      0                                                /var/run/cilium/envoy/sockets/admin.sock 29340            * 28672

cilium-agentê°€ Envoyì˜ XDS(xds.sock) ë° admin(admin.sock) ì†Œì¼“ê³¼ ì—°ê²°ë˜ì–´ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

kc describe cm -n kube-system cilium-envoy-config
...
Data
====
bootstrap-config.json:
----
{"admin":{"address":{"pipe":{"path":"/var/run/cilium/envoy/sockets/admin.sock"}}}...
...

bootstrap-config.jsonì—ì„œ Envoy Bootstrap ì„¤ì •(ê´€ë¦¬ ì†Œì¼“ ê²½ë¡œ ë“±)ì˜ ì„¸ë¶€ ë‚´ìš©ì„ ê²€í† í•©ë‹ˆë‹¤.

## Apply and Test HTTP-aware L7 Policy

> HTTP ê³„ì¸µ(L7) ì •ì±…ì„ ì ìš©í•˜ì—¬, íƒ€ì´íŒŒì´í„°ê°€ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” URLì„ **POST /v1/request-landing** ìœ¼ë¡œ ì œí•œí•˜ê³ , ê·¸ ì™¸(ì˜ˆ: PUT /v1/exhaust-port) í˜¸ì¶œì„ ì°¨ë‹¨í•©ë‹ˆë‹¤.

---

### 1. L3/L4 ëª¨ë‹ˆí„°ë§ë§Œìœ¼ë¡œëŠ” HTTP ê²½ë¡œë¥¼ êµ¬ë¶„í•  ìˆ˜ ì—†ìŒ

```bash
# ëª¨ë‹ˆí„°ë§ >> Layer3/4 ì—ì„œëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœë¥¼ í™•ì¸ í•  ìˆ˜ ì—†ìŒ!
hubble observe -f --protocol tcp --from-identity $DEATHSTARID

# í˜¸ì¶œí•´ì„œëŠ” ì•ˆ ë˜ëŠ” ì¼ë¶€ ìœ ì§€ë³´ìˆ˜ APIë¥¼ ë…¸ì¶œ
kubectl exec tiefighter -- curl -s -XPUT deathstar.default.svc.cluster.local/v1/exhaust-port


â¸»

2. L7-aware ì •ì±… ì •ì˜ (rule1 ì—…ë°ì´íŠ¸)

# ê¸°ì¡´ rule1 ì •ì±…ì„ ì—…ë°ì´íŠ¸ í•´ì„œ ì‚¬ìš©
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "L7 policy to restrict access to specific HTTP call"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - fromEndpoints:
    - matchLabels:
        org: empire
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP
      rules:
        http:
        - method: "POST"
          path: "/v1/request-landing"

# Update the existing rule to apply L7-aware policy to protect deathstar using:
kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/sw_l3_l4_l7_policy.yaml
kubectl get cnp
kc describe cnp
c0 policy get


â¸»

3. HTTP í”Œë¡œìš° ê´€ì°° ë° í…ŒìŠ¤íŠ¸

# ëª¨ë‹ˆí„°ë§ : íŒŒë“œ ì´ë¦„ ì§€ì •
hubble observe -f --pod deathstar --protocol http
Jul 20 01:28:02.184: default/tiefighter:59020 (ID:19274) -> default/deathstar-8c4c77fb7-9klws:80 (ID:318) http-request FORWARDED (HTTP/1.1 POST http://deathstar.default.svc.cluster.local/v1/request-landing)
Jul 20 01:28:02.190: default/tiefighter:59020 (ID:19274) <- default/deathstar-8c4c77fb7-9klws:80 (ID:318) http-response FORWARDED (HTTP/1.1 200 6ms (POST http://deathstar.default.svc.cluster.local/v1/request-landing))

# We can now re-run the same test as above, but we will see a different outcome
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing


â¸»

4. ì°¨ë‹¨ëœ L7 íŠ¸ë˜í”½ ê´€ì°°

# ëª¨ë‹ˆí„°ë§ : íŒŒë“œ ì´ë¦„ ì§€ì •
hubble observe -f --pod deathstar --verdict DROPPED
Jul 20 01:31:21.248: default/tiefighter:44734 (ID:19274) -> default/deathstar-8c4c77fb7-9klws:80 (ID:318) http-request DROPPED (HTTP/1.1 PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port)

í˜¹ì€
c1 monitor -v --type l7
<- Request http from 3845 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) to 871 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 19274->318, verdict Denied PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port => 0
<- Response http to 3845 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) from 871 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 318->19274, verdict Forwarded PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port => 403
c2 monitor -v --type l7

ìœ„ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ POST ìš”ì²­ë§Œ FORWARDED ë˜ê³ , PUT ìš”ì²­ì€ L7 ì •ì±…ì— ì˜í•´ DROPPED(ë˜ëŠ” 403) ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Re-run Test & Observations

> L7 ì •ì±… ì ìš© í›„ PUT ìš”ì²­ì´ ê±°ë¶€ë˜ê³ , POST ìš”ì²­ì´ ì •ìƒ ì²˜ë¦¬ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

```bash
# We can now re-run the same test as above, but we will see a different outcome
kubectl exec tiefighter -- curl -s -XPUT deathstar.default.svc.cluster.local/v1/exhaust-port
Access denied



# ëª¨ë‹ˆí„°ë§ : íŒŒë“œ ì´ë¦„ ì§€ì •
hubble observe -f --pod xwing

# í˜¸ì¶œ ì‹œë„ : ìœ„ì™€ ì•„ë˜ ì‹¤í–‰ ì¢…ë£Œì˜ ì°¨ì´ì ì„ ì´í•´í•´ë³´ì!
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing --connect-timeout 2


â¸»

Resource Cleanup

ë‹¤ìŒ ì‹¤ìŠµì„ ìœ„í•´ ìƒì„±ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¦¬ì†ŒìŠ¤ì™€ ì •ì±…ì„ ì‚­ì œí•©ë‹ˆë‹¤.

# ë‹¤ìŒ ì‹¤ìŠµì„ ìœ„í•´ ë¦¬ì†ŒìŠ¤ ì‚­ì œ
kubectl delete -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/http-sw-app.yaml
kubectl delete cnp rule1

# ì‚­ì œ í™•ì¸
kubectl get cnp


â¸»

Configuring Hubble Exporter

Hubble íë¦„ ë¡œê·¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê³ , ë¡œê·¸ íšŒì „(rotation), í¬ê¸° ì œí•œ, í•„í„°, í•„ë“œ ë§ˆìŠ¤í¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
ì´ ì„¤ì •ì€ Hubble ì„¤ì¹˜ ì‹œ ì´ë¯¸ ê¸°ë³¸ ì ìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

# ì„¤ì • : ì•„ë˜ ì„¤ì •í•  í•„ìš” ì—†ìŒ
helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
   --set hubble.enabled=true \
   --set hubble.export.static.enabled=true \
   --set hubble.export.static.filePath=/var/run/cilium/hubble/events.log

kubectl -n kube-system rollout status ds/cilium

# í™•ì¸
kubectl get cm -n kube-system cilium-config -o json | grep hubble-export
cilium config view | grep hubble-export
hubble-export-allowlist                           
hubble-export-denylist                            
hubble-export-fieldmask                           
hubble-export-file-max-backups   # number of rotated Hubble export files to keep. (default 5)
hubble-export-file-max-size-mb   # size in MB at which to rotate the Hubble export file. (default 10)
hubble-export-file-path          # file path of target log file. (default /var/run/cilium/hubble/events.log)

# Verify that flow logs are stored in target files
kubectl -n kube-system exec ds/cilium -- tail -f /var/run/cilium/hubble/events.log
kubectl -n kube-system exec ds/cilium -- sh -c 'tail -f /var/run/cilium/hubble/events.log' | jq

## Performance Tuning for Hubble Exporter

> Hubble Exporterì˜ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ì„¤ì •í•  ìˆ˜ ìˆëŠ” ì£¼ìš” ì˜µì…˜ê³¼ êµ¬ì„± ì˜ˆì‹œì…ë‹ˆë‹¤.

### ì£¼ìš” ì„¤ì • ì˜µì…˜
- `hubble.export.static.allowList`  
  JSON ì¸ì½”ë”©ëœ FlowFiltersë¡œ **í—ˆìš© ë¦¬ìŠ¤íŠ¸** ì§€ì •
- `hubble.export.static.denyList`  
  JSON ì¸ì½”ë”©ëœ FlowFiltersë¡œ **ì°¨ë‹¨ ë¦¬ìŠ¤íŠ¸** ì§€ì •
- `hubble.export.static.fieldMask`  
  Flow í”„ë¡œí†  ì •ì˜ì˜ í•„ë“œ ì´ë¦„ **ë¦¬ìŠ¤íŠ¸**ë¡œ **í•„ë“œ ë§ˆìŠ¤í‚¹** ì§€ì •

> Field maskëŠ” [flow proto](https://github.com/cilium/cilium/blob/main/api/v1/flow/flow.proto) ì •ì˜ì˜ í•„ë“œ ì´ë¦„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

---

## Static Exporter: Filters & Field Masks

> `hubble observe --print-raw-filters` ëª…ë ¹ì„ í™œìš©í•´ í•„ìš”í•œ í•„í„° ì¡°ê±´ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# You can use hubble CLI to generated required filters (see Specifying Raw Flow Filters for more examples).
# For example, to filter flows with verdict DENIED or ERROR, run:
hubble observe --verdict DROPPED --verdict ERROR --print-raw-filters
allowlist:
- '{"verdict":["DROPPED","ERROR"]}'

ìœ„ ì˜ˆì‹œëŠ” verdictê°€ DROPPED ë˜ëŠ” ERRORì¸ í”Œë¡œìš°ë§Œ ë¡œê¹…í•˜ë„ë¡ í•˜ëŠ” í—ˆìš© ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

# To keep all information except pod labels:
hubble-export-fieldmask: time source.identity source.namespace source.pod_name destination.identity destination.namespace destination.pod_name source_service destination_service l4 IP ethernet l7 Type node_name is_reply event_type verdict Summary

# To keep only timestamp, verdict, ports, IP addresses, node name, pod name, and namespace:
hubble-export-fieldmask: time source.namespace source.pod_name destination.namespace destination.pod_name l4 IP node_name is_reply verdict

ì²« ë²ˆì§¸ í•„ë“œ ë§ˆìŠ¤í¬ëŠ” pod ë¼ë²¨ì„ ì œì™¸í•œ ëª¨ë“  ì •ë³´ë¥¼,
ë‘ ë²ˆì§¸ëŠ” ìµœì†Œí•œì˜ ì •ë³´(íƒ€ì„ìŠ¤íƒ¬í”„, í¬ë“œ/ë„¤ì„ìŠ¤í˜ì´ìŠ¤, í¬íŠ¸, IP, ë…¸ë“œëª…, ì‘ë‹µ ì—¬ë¶€, verdict)ë§Œ ìœ ì§€í•©ë‹ˆë‹¤.

â¸»

Static Exporter êµ¬ì„± ë°©ë²•

ë°©ë²• 1: ConfigMap ì§ì ‘ íŒ¨ì¹˜

# ì„¤ì • ë°©ì•ˆ 1 : Then paste the output to hubble-export-allowlist in cilium-config Config Map:
kubectl -n kube-system patch cm cilium-config --patch-file=/dev/stdin <<-EOF
data:
  hubble-export-allowlist: '{"verdict":["DROPPED","ERROR"]}'
  hubble-export-denylist: '{"source_pod":["kube-system/"]},{"destination_pod":["kube-system/"]}'
EOF

cilium-config ConfigMapì— ì§ì ‘ í—ˆìš©/ì°¨ë‹¨ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

â¸»

ë°©ë²• 2: Helm ì—…ê·¸ë ˆì´ë“œ

# ì„¤ì • ë°©ì•ˆ 2 : helm ì—…ê·¸ë ˆì´ë“œ
helm upgrade cilium cilium/cilium --version 1.17.6 \
   --set hubble.enabled=true \
   --set hubble.export.static.enabled=true \
   --set hubble.export.static.filePath=/var/run/cilium/hubble/events.log \
   --set hubble.export.static.allowList[0]='{"verdict":["DROPPED","ERROR"]}' \
   --set hubble.export.static.denyList[0]='{"source_pod":["kube-system/"]}' \
   --set hubble.export.static.denyList[1]='{"destination_pod":["kube-system/"]}' \
   --set "hubble.export.static.fieldMask={time,source.namespace,source.pod_name,destination.namespace,destination.pod_name,l4,IP,node_name,is_reply,verdict,drop_reason_desc}"

Helm ì°¨íŠ¸ë¥¼ í†µí•´ static exporterì˜ allowList, denyList, fieldMaskë¥¼ í•œ ë²ˆì— êµ¬ì„±í•©ë‹ˆë‹¤.

# í™•ì¸
cilium config view | grep hubble-export
hubble-export-allowlist                           {"verdict":["DENIED","ERROR"]}
...

kubectl -n kube-system exec ds/cilium -- tail -f /var/run/cilium/hubble/events.log
{"flow":{"time":"2023-08-21T12:12:13.517394084Z","verdict":"DROPPED","IP":{"source":"fe80::64d8:8aff:fe72:fc14","destination":"ff02::2","ipVersion":"IPv6"},"l4":{"ICMPv6":{"type":133}},"source":{},"destination":{},"node_name":"kind-kind/kind-worker","drop_reason_desc":"INVALID_SOURCE_IP"},"node_name":"kind-kind/kind-worker","time":"2023-08-21T12:12:13.517394084Z"}
{"flow":{"time":"2023-08-21T12:12:18.510175415Z","verdict":"DROPPED","IP":{"source":"10.244.1.60","destination":"10.244.1.5","ipVersion":"IPv4"},"l4":{"TCP":{"source_port":44916,"destination_port":80,"flags":{"SYN":true}}},"source":{"namespace":"default","pod_name":"xwing"},"destination":{"namespace":"default","pod_name":"deathstar-7848d6c4d5-th9v2"},"node_name":"kind-kind/kind-worker","drop_reason_desc":"POLICY_DENIED"},"node_name":"kind-kind/kind-worker","time":"2023-08-21T12:12:18.510175415Z"}

ì„¤ì •ì´ ë°˜ì˜ëœ í›„ Hubble flows ë¡œê·¸ì— POLICY_DENIED ë“±ì˜ ì´ë²¤íŠ¸ë§Œ ê¸°ë¡ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.

â¸»

Dynamic Exporter Configuration

Pod ì¬ì‹œì‘ ì—†ì´ ë™ì ìœ¼ë¡œ ì—¬ëŸ¬ í•„í„°ë¥¼ êµ¬ì„±í•˜ê³ , ë³„ë„ íŒŒì¼ë¡œ ë¡œê·¸ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# Dynamic exporter í™œì„±í™”
helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
   --set hubble.enabled=true \
   --set hubble.export.static.enabled=false \
   --set hubble.export.dynamic.enabled=true

kubectl -n kube-system rollout status ds/cilium

static exporterë¥¼ ë¹„í™œì„±í™”í•˜ê³  dynamic exporterë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤.

# Dynamic flow logs ì˜ˆì‹œ: system íë¦„ì„ ë³„ë„ íŒŒì¼ì— ì €ì¥í•˜ê³  kube-system ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í•„í„° ì ìš©
helm upgrade cilium cilium/cilium --version 1.17.6 \
   --set hubble.enabled=true \
   --set hubble.export.dynamic.enabled=true \
   --set hubble.export.dynamic.config.content[0].name=system \
   --set hubble.export.dynamic.config.content[0].filePath=/var/run/cilium/hubble/events-system.log \
   --set hubble.export.dynamic.config.content[0].includeFilters[0].source_pod[0]='kube_system/' \
   --set hubble.export.dynamic.config.content[0].includeFilters[1].destination_pod[0]='kube_system/'

# Dynamic exporterëŠ” end property, field masking ë“± staticê³¼ ë™ì¼í•œ ê¸°ëŠ¥ì„ ì§€ì›í•˜ë©°,
# maxOutputFileSizeMb ë° fileMaxBackupsëŠ” static ì„¤ì •ì„ ì¬í™œìš©í•©ë‹ˆë‹¤.

Dynamic exporterë¥¼ ì‚¬ìš©í•˜ë©´ ì—¬ëŸ¬ í•„í„° ì„¸íŠ¸ë¥¼ ë™ì‹œì— ê´€ë¦¬í•˜ê³ , êµ¬ì„± ë³€ê²½ì„ ìœ„í•´ Pod ì¬ì‹œì‘ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
## 2.1 ìƒ˜í”Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬

> ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì—­í• ì„ í•˜ëŠ” `webpod` Deployment(2 ë³µì œë³¸)ì™€ ClusterIP Serviceë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  
> `podAntiAffinity` ì„¤ì •ìœ¼ë¡œ ë™ì¼ í˜¸ìŠ¤íŠ¸ì— ì¤‘ë³µ ë°°ì¹˜ë˜ì§€ ì•Šë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.

```bash
# ìƒ˜í”Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
EOF


â¸»

2.2 curl-pod ë°°í¬

k8s-ctr ë…¸ë“œì—ì„œ HTTP ìš”ì²­ì„ ë³´ë‚¼ ìˆ˜ ìˆëŠ” curl-podë¥¼ ë°°í¬í•©ë‹ˆë‹¤.
nicolaka/netshoot ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ë„¤íŠ¸ì›Œí¬ ë„êµ¬ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# k8s-ctr ë…¸ë“œì— curl-pod íŒŒë“œ ë°°í¬
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
EOF


â¸»

2.3 ë°°í¬ í™•ì¸ ë° í†µì‹  í…ŒìŠ¤íŠ¸

ìƒì„±ëœ ë¦¬ì†ŒìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•˜ê³ , curl-podì—ì„œ webpod ì„œë¹„ìŠ¤ë¡œ ìš”ì²­ì„ ë°˜ë³µí•˜ì—¬ ì‘ë‹µì„ ê²€ì¦í•©ë‹ˆë‹¤.

# ë°°í¬ í™•ì¸
kubectl get deploy,svc,ep webpod -owide
kubectl get endpointslices -l app=webpod
kubectl get ciliumendpoints
kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- cilium-dbg endpoint list

# í†µì‹  í™•ì¸
kubectl exec -it curl-pod -- curl webpod | grep Hostname
kubectl exec -it curl-pod -- sh -c 'while true; do curl -s webpod | grep Hostname; sleep 1; done'

ìœ„ í™•ì¸ ê³¼ì •ì„ í†µí•´:
	â€¢	Deployment/Service/Endpointê°€ ì •ìƒ ìƒì„±ë˜ì—ˆëŠ”ì§€,
	â€¢	Cilium CNI ê´€ì ì—ì„œ Endpointê°€ ë“±ë¡ë˜ì—ˆëŠ”ì§€,
	â€¢	curl-podì—ì„œ webpodë¡œ ìš”ì²­ ì‹œ ê° íŒŒë“œì˜ Hostnameì´ ë°˜ë³µ ì¶œë ¥ë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
## 3. Install Prometheus & Grafana

> Prometheusì™€ Grafanaë¥¼ í•˜ë‚˜ì˜ ë°°í¬ë¡œ í¬í•¨í•œ ì˜ˆì œì…ë‹ˆë‹¤.  
> ì´ ë°°í¬ëŠ” **Cilium** ë° **Hubble** ë©”íŠ¸ë¦­ì„ ìë™ìœ¼ë¡œ ìŠ¤í¬ë©í•˜ë„ë¡ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  
> - **Grafana**: Cilium Dashboardê°€ ë¯¸ë¦¬ ë¡œë“œëœ ì‹œê°í™” ëŒ€ì‹œë³´ë“œ  
> - **Prometheus**: ì‹œê³„ì—´ ë°ì´í„°ë² ì´ìŠ¤ ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ  

```bash
#
kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes/addons/prometheus/monitoring-example.yaml
configmap/grafana-config created
configmap/grafana-cilium-dashboard created
configmap/grafana-cilium-operator-dashboard created
configmap/grafana-hubble-dashboard created
configmap/grafana-hubble-l7-http-metrics-by-workload created
configmap/prometheus created

#
kubectl get deploy,pod,svc,ep -n cilium-monitoring
kubectl get cm -n cilium-monitoring
NAME                                         DATA   AGE
grafana-cilium-dashboard                     1      113s
grafana-cilium-operator-dashboard            1      113s
grafana-config                               3      113s
grafana-hubble-dashboard                     1      113s
grafana-hubble-l7-http-metrics-by-workload   1      113s
prometheus                                   1      113s

# í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ ì„¤ì • í™•ì¸
kc describe cm -n cilium-monitoring prometheus

# ê·¸ë¼íŒŒë‚˜ ì„œë²„ ì„¤ì • í™•ì¸
kc describe cm -n cilium-monitoring grafana-config

# Grafana ëŒ€ì‹œë³´ë“œ ì£¼ì… ConfigMap í™•ì¸
kc describe cm -n cilium-monitoring grafana-cilium-dashboard
kc describe cm -n cilium-monitoring grafana-hubble-dashboard
...

ìœ„ ëª…ë ¹ìœ¼ë¡œ cilium-monitoring ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— Prometheus, Grafana, ê·¸ë¦¬ê³  ê´€ë ¨ ConfigMapë“¤ì´ ìƒì„± ë° ì£¼ì…ë˜ì—ˆìŒì„ í™•ì¸í•©ë‹ˆë‹¤.

â¸»

4. Cilium & Hubble ë©”íŠ¸ë¦­ í™œì„±í™”

Cilium, Cilium-Operator, HubbleëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë©”íŠ¸ë¦­ì„ ë…¸ì¶œí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, Helm ê°’ì„ í†µí•´ í¬íŠ¸(9962, 9963, 9965)ë¥¼ ì—´ì–´ ìŠ¤í¬ë˜í•‘í•˜ë„ë¡ í•©ë‹ˆë‹¤.

# ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŒ
helm install cilium cilium/cilium --version 1.17.6 \
   --namespace kube-system \
   --set prometheus.enabled=true \
   --set operator.prometheus.enabled=true \
   --set hubble.enabled=true \
   --set hubble.metrics.enableOpenMetrics=true \
   --set hubble.metrics.enabled="{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip\,source_namespace\,source_workload\,destination_ip\,destination_namespace\,destination_workload\,traffic_direction}"

# í˜¸ìŠ¤íŠ¸ì—ì„œ ë©”íŠ¸ë¦­ í¬íŠ¸ ì—´ë¦¼ í™•ì¸
ss -tnlp | grep -E '9962|9963|9965'
LISTEN 0      4096                *:9963             *:*    users:(("cilium-operator",pid=1488,fd=7)) # cilium-operator ë©”íŠ¸ë¦­        
LISTEN 0      4096                *:9962             *:*    users:(("cilium-agent",pid=1894,fd=7))    # cilium ë©”íŠ¸ë¦­  
LISTEN 0      4096                *:9965             *:*    users:(("cilium-agent",pid=1894,fd=40))   # hubble ë©”íŠ¸ë¦­

# ì›Œì»¤ ë…¸ë“œë³„ í¬íŠ¸ í™•ì¸
for i in w1 w2 ; do
  echo ">> node : k8s-$i <<"
  sshpass -p 'vagrant' ssh vagrant@k8s-$i sudo ss -tnlp | grep -E '9962|9963|9965'
  echo
done

ìœ„ í™•ì¸ì„ í†µí•´ ê° ë…¸ë“œì—ì„œ Cilium ì»´í¬ë„ŒíŠ¸ì˜ ë©”íŠ¸ë¦­ í¬íŠ¸ê°€ ì •ìƒì ìœ¼ë¡œ ì—´ë ¸ìŒì„ ê²€ì¦í•©ë‹ˆë‹¤.

â¸»

5. NodePortë¥¼ í†µí•œ ì™¸ë¶€ ì ‘ì†

í˜¸ìŠ¤íŠ¸ PCì—ì„œ Prometheus ë° Grafana UIì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ NodePortë¡œ Service íƒ€ì…ì„ ë³€ê²½í•©ë‹ˆë‹¤.

#
kubectl get svc -n cilium-monitoring
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
grafana      ClusterIP   10.96.212.137   <none>        3000/TCP   6m36s
prometheus   ClusterIP   10.96.240.147   <none>        9090/TCP   6m36s

# NodePort ì„¤ì •
kubectl patch svc -n cilium-monitoring prometheus -p '{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}'
kubectl patch svc -n cilium-monitoring grafana -p '{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}'

# ì„¤ì • í™•ì¸
kubectl get svc -n cilium-monitoring
NAME         TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
grafana      NodePort   10.96.212.137   <none>        3000:30002/TCP   14m
prometheus   NodePort   10.96.240.147   <none>        9090:30001/TCP   14m

# ì ‘ì† ì£¼ì†Œ ì˜ˆì‹œ (ë…¸ë“œ eth1 IP ì‚¬ìš©)s
echo "http://192.168.10.100:30001"  # Prometheus
echo "http://192.168.10.100:30002"  # Grafana

ìœ„ ê³¼ì •ì„ í†µí•´ ë¸Œë¼ìš°ì €ì—ì„œ http://<ë…¸ë“œ_IP>:30001 ë° http://<ë…¸ë“œ_IP>:30002 ë¡œ Prometheusì™€ Grafana UIì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.