


---


## 2Ï£ºÏ∞® Ïã§Ïäµ ÌôòÍ≤Ω Í∞úÏöî

![Ïã§Ïäµ ÌôòÍ≤Ω Í∞úÏöî](image.png)

- **Í∏∞Î≥∏ Î∞∞Í∏∞Í∏∞Ìè¨ Í∞ÄÏÉÅ Î®∏Ïã†** : k8s-ctr, k8s-w1, k8s-w2
- **Ï¥àÍ∏∞ ÌîÑÎ°úÎπÑÏ†ÄÎãù** : kubeadm init, join Ïã§Ìñâ
- **Cilium CNI** ÏÑ§Ïπò ÏÉÅÌÉúÎ°ú Î∞∞Ìè¨ ÏôÑÎ£å

---

## Ïã§Ïäµ ÌôòÍ≤Ω Î∞∞Ìè¨ ÌååÏùº ÏûëÏÑ±

- **Vagrantfile** : Í∞ÄÏÉÅÎ®∏Ïã† Ï†ïÏùò, Î∂ÄÌåÖ Ïãú Ï¥àÍ∏∞ ÌîÑÎ°úÎπÑÏ†ÄÎãù ÏÑ§Ï†ï
- **init_cfg.sh** : args Ï∞∏Í≥†ÌïòÏó¨ ÏÑ§Ïπò
- **k8s-ctr.sh** : kubeadm init, Cilium CNI ÏÑ§Ïπò, Ìé∏Î¶¨ÏÑ± ÏÑ§Ï†ï(k, kc)
- **k8s-w.sh** : kubeadm join

```bash
mkdir cilium-lab && cd cilium-lab
curl -O https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/Vagrantfile
vagrant up
```

---

## Ïã§Ïäµ ÌôòÍ≤Ω Î∞∞Ìè¨ Î∞è Ï¥àÍ∏∞ Ï†êÍ≤Ä

```bash
# /etc/hosts ÌôïÏù∏
cat /etc/hosts

# Í∞Å ÏõåÏª§ ÎÖ∏Îìú Ï†ëÏÜç ÌÖåÏä§Ìä∏
sshpass -p 'vagrant' ssh -o StrictHostKeyChecking=no vagrant@k8s-w1 hostname
sshpass -p 'vagrant' ssh -o StrictHostKeyChecking=no vagrant@k8s-w2 hostname

# ÎÑ§Ìä∏ÏõåÌÅ¨ Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ ÌôïÏù∏
ifconfig | grep -iEA1 'eth[0-9]:'

# ÌÅ¥Îü¨Ïä§ÌÑ∞ Ï†ïÎ≥¥ ÌôïÏù∏
kubectl cluster-info
kubectl cluster-info dump | grep -m 2 -E "cluster-cidr|service-cluster-ip-range"
kubectl describe cm -n kube-system kubeadm-config
kubectl describe cm -n kube-system kubelet-config

# ÎÖ∏Îìú Ï†ïÎ≥¥ : ÏÉÅÌÉú, INTERNAL-IP ÌôïÏù∏
kubectl get node -owide

# ÎÖ∏ÎìúÎ≥Ñ kubeadm-flags.env Ï†ïÎ≥¥ ÌôïÏù∏
cat /var/lib/kubelet/kubeadm-flags.env
for i in w1 w2 ; do echo ">> node : k8s-$i <<"; sshpass -p 'vagrant' ssh vagrant@k8s-$i cat /var/lib/kubelet/kubeadm-flags.env ; echo; done

# ÌååÎìú Ï†ïÎ≥¥ : ÏÉÅÌÉú, ÌååÎìú IP ÌôïÏù∏
kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'
kubectl get ciliumnode -o json | grep podCIDRs -A2
kubectl get pod -A -owide

# iptables ÌôïÏù∏
iptables-save
iptables -t nat -S
iptables -t filter -S
iptables -t mangle -S
```


---

## k8s-ctr - Cilium ÏÑ§Ïπò Ï†ïÎ≥¥ ÌôïÏù∏

```bash
# cilium ÏÉÅÌÉú ÌôïÏù∏
which cilium
cilium status
cilium config view
kubectl get cm -n kube-system cilium-config -o json | jq

# ÏÉÅÏÑ∏ ÏÉÅÌÉú/Î©îÌä∏Î¶≠
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg config
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg status --verbose
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg metrics list

# ÏóîÎìúÌè¨Ïù∏Ìä∏ Ï†ïÎ≥¥
kubectl get ciliumendpoints -A

# Î™®ÎãàÌÑ∞ÎßÅ
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v -v

## ÏóîÎìúÌè¨Ïù∏Ìä∏Î≥Ñ Î™®ÎãàÌÑ∞ÎßÅ/ÎìúÎ°≠/HEX
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor --related-to=<id>
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor --type drop
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v -v --hex
```

## Layer 7 Î™®ÎãàÌÑ∞ÎßÅ

```bash
# Layer 7 Ìä∏ÎûòÌîΩ Î™®ÎãàÌÑ∞ÎßÅ
kubectl exec -n kube-system -c cilium-agent -it ds/cilium -- cilium-dbg monitor -v --type l7
```

---

## 1. Network Observability with Hubble

### Hubble ÏÜåÍ∞ú
- **CiliumÏùò Í¥ÄÏ∏° Í∞ÄÎä•ÏÑ± ÌîåÎû´Ìèº**
- **ÎÑ§Ìä∏ÏõåÌÅ¨ Ìä∏ÎûòÌîΩ Í∞ÄÏãúÏÑ±** Ï†úÍ≥µ
- **Ïã§ÏãúÍ∞Ñ ÌîåÎ°úÏö∞ Î™®ÎãàÌÑ∞ÎßÅ** Í∏∞Îä•

### Setting up Hubble Observability

#### üìã ÏÑ§Ïπò Ï†Ñ ÌôïÏù∏

```bash
# Cilium ÏÉÅÌÉú ÌôïÏù∏
cilium status
cilium config view | grep -i hubble
kubectl get cm -n kube-system cilium-config -o json | jq

# Í∏∞Ï°¥ Secret Î∞è Ìè¨Ìä∏ ÌôïÏù∏
kubectl get secret -n kube-system | grep -iE 'cilium-ca|hubble'
ss -tnlp | grep -iE 'cilium|hubble' | tee before.txt
```

#### üöÄ Hubble ÏÑ§Ïπò

##### ÏÑ§ÏπòÎ∞©Ïïà 1: HelmÏùÑ ÌÜµÌïú ÏôÑÏ†Ñ ÏÑ§Ïπò

```bash
# hubble ÌôúÏÑ±Ìôî, Î©îÌä∏Î¶≠ ÏÑ§Ï†ï Îì±Îì±
helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
--set hubble.enabled=true \
--set hubble.relay.enabled=true \
--set hubble.ui.enabled=true \
--set hubble.ui.service.type=NodePort \
--set hubble.ui.service.nodePort=31234 \
--set hubble.export.static.enabled=true \
--set hubble.export.static.filePath=/var/run/cilium/hubble/events.log \
--set prometheus.enabled=true \
--set operator.prometheus.enabled=true \
--set hubble.metrics.enableOpenMetrics=true \
--set hubble.metrics.enabled="{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip\,source_namespace\,source_workload\,destination_ip\,destination_namespace\,destination_workload\,traffic_direction}"

# ÏÑ§ÏπòÎ∞©Ïïà 2 : hubble ÌôúÏÑ±Ìôî
cilium hubble enable
cilium hubble enable --ui


# This is required for Relay to operate correctly.
cilium status
Hubble Relay:       OK

#
cilium config view | grep -i hubble
kubectl get cm -n kube-system cilium-config -o json | grep -i hubble

#
kubectl get secret -n kube-system | grep -iE 'cilium-ca|hubble'

# # Enabling Hubble requires the TCP port 4244 to be open on all nodes running Cilium.
ss -tnlp | grep -iE 'cilium|hubble' | tee after.txt
vi -d before.txt after.txt
for i in w1 w2 ; do echo ">> node : k8s-$i <<"; sshpass -p 'vagrant' ssh vagrant@k8s-$i sudo ss -tnlp |grep 4244 ; echo; done

#
kubectl get pod -n kube-system -l k8s-app=hubble-relay
kc describe pod -n kube-system -l k8s-app=hubble-relay

kc get svc,ep -n kube-system hubble-relay
...
NAME                     ENDPOINTS           AGE
endpoints/hubble-relay   172.20.1.202:4245   7m54s


# hubble-relay Îäî hubble-peer Ïùò ÏÑúÎπÑÏä§(ClusterIP :443)ÏùÑ ÌÜµÌï¥ Î™®Îì† ÎÖ∏ÎìúÏùò :4244Ïóê ÏöîÏ≤≠ Í∞ÄÏ†∏Ïò¨ Ïàò ÏûàÏùå
kubectl get cm -n kube-system
kubectl describe cm -n kube-system hubble-relay-config
...
cluster-name: default
peer-service: "hubble-peer.kube-system.svc.cluster.local.:443"
listen-address: :4245
...

#
kubectl get svc,ep -n kube-system hubble-peer
NAME                  TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE
service/hubble-peer   ClusterIP   10.96.145.0   <none>        443/TCP   5h55m

NAME                    ENDPOINTS                                                     AGE
endpoints/hubble-peer   192.168.10.100:4244,192.168.10.101:4244,192.168.10.102:4244   5h55m

#
kc describe pod -n kube-system -l k8s-app=hubble-ui
...
Containers:
frontend:
...
backend:
...

kc describe cm -n kube-system hubble-ui-nginx
...

#
kubectl get svc,ep -n kube-system hubble-ui
NAME                TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE
service/hubble-ui   NodePort   10.96.66.67   <none>        80:31234/TCP   17m

NAME                  ENDPOINTS          AGE
endpoints/hubble-ui   172.20.2.70:8081   17m

# hubble ui Ïõπ Ï†ëÏÜç Ï£ºÏÜå ÌôïÏù∏
NODEIP=$(ip -4 addr show eth1 | grep -oP '(?<=inet\s)\d+(\.\d+){3}')
echo -e "http://$NODEIP:31234"
```

- Hubble Client ÏÑ§Ïπò
- - **Validate Hubble API Access**
    - In order to **access** the **Hubble API**, create a port forward to the Hubble service from **your local machine.**
    - This will allow you to connect the **Hubble client** to the local port¬†`4245`¬†and access the **Hubble Relay service** in your Kubernetes cluster.
    - For more information on this method, see¬†[Use Port Forwarding to Access Application in a Cluster](https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/).
```
  #
  cilium hubble port-forward&
  Hubble Relay is available at 127.0.0.1:4245
  
  ss -tnlp | grep 4245
  
  # Now you can validate that you can access the Hubble API via the installed CLI
  hubble status
  Healthcheck (via localhost:4245): Ok
  Current/Max Flows: 12,285/12,285 (100.00%)
  Flows/s: 41.20
  
  # hubble (api) server Í∏∞Î≥∏ Ï†ëÏÜç Ï£ºÏÜå ÌôïÏù∏
  hubble config view 
  ...
  port-forward-port: "4245"
  server: localhost:4245
  ...
  
  # (ÏòµÏÖò) ÌòÑÏû¨ k8s-ctr Í∞ÄÏÉÅÎ®∏Ïã†Ïù¥ ÏïÑÎãå, ÏûêÏã†Ïùò PCÏóê kubeconfig ÏÑ§Ï†ï ÌõÑ ÏïÑÎûò --server ÏòµÏÖòÏùÑ ÌÜµÌï¥ hubble api server ÏÇ¨Ïö©Ìï¥Î≥¥Ïûê!
  hubble help status | grep 'server string'
        --server string                 Address of a Hubble server. Ignored when --input-file or --port-forward is provided. (default "localhost:4245")
  
  # You can also query the flow API and look for flows
  kubectl get ciliumendpoints.cilium.io -n kube-system # SECURITY IDENTITY
  hubble observe
  hubble observe -h
  hubble observe -f
```
- Cilium Agent Îã®Ï∂ïÌÇ§ ÏßÄÏ†ï
```
[- Cilium Agent Îã®Ï∂ïÌÇ§ ÏßÄÏ†ï„Ñπ„Öá„Ñ¥„ÖÅ„Ñπ„Öá„Ñ¥„ÖÅ„Ñπ„Öá„Ñ¥„ÖÅ„Ñπ](<# cilium ÌååÎìú Ïù¥Î¶Ñ
export CILIUMPOD0=$(kubectl get -l k8s-app=cilium pods -n kube-system --field-selector spec.nodeName=k8s-ctr -o jsonpath='{.items[0].metadata.name}')
export CILIUMPOD1=$(kubectl get -l k8s-app=cilium pods -n kube-system --field-selector spec.nodeName=k8s-w1  -o jsonpath='{.items[0].metadata.name}')
export CILIUMPOD2=$(kubectl get -l k8s-app=cilium pods -n kube-system --field-selector spec.nodeName=k8s-w2  -o jsonpath='{.items[0].metadata.name}')
echo $CILIUMPOD0 $CILIUMPOD1 $CILIUMPOD2

# Îã®Ï∂ïÌÇ§(alias) ÏßÄÏ†ï
alias c0="kubectl exec -it $CILIUMPOD0 -n kube-system -c cilium-agent -- cilium"
alias c1="kubectl exec -it $CILIUMPOD1 -n kube-system -c cilium-agent -- cilium"
alias c2="kubectl exec -it $CILIUMPOD2 -n kube-system -c cilium-agent -- cilium"

alias c0bpf="kubectl exec -it $CILIUMPOD0 -n kube-system -c cilium-agent -- bpftool"
alias c1bpf="kubectl exec -it $CILIUMPOD1 -n kube-system -c cilium-agent -- bpftool"
alias c2bpf="kubectl exec -it $CILIUMPOD2 -n kube-system -c cilium-agent -- bpftool"


# endpoint
c0 endpoint list
c0 endpoint list -o json
c1 endpoint list
c2 endpoint list

c1 endpoint get %3Cid%3E
c1 endpoint log <id>

## Enable debugging output on the cilium-dbg monitor for this endpoint
c1 endpoint config <id> Debug=true


# monitor
c1 monitor
c1 monitor -v
c1 monitor -v -v

## Filter for only the events related to endpoint
c1 monitor --related-to=<id>

## Show notifications only for dropped packet events
c1 monitor --type drop

## Don‚Äôt dissect packet payload, display payload in hex information
c1 monitor -v -v --hex

## Layer7
c1 monitor -v --type l7


# Manage IP addresses and associated information - IP List
c0 ip list

# IDENTITY :  1(host), 2(world), 4(health), 6(remote), ÌååÎìúÎßàÎã§ Í∞úÎ≥Ñ ID
c0 ip list -n

# Retrieve information about an identity
c0 identity list

# ÏóîÎìúÌè¨Ïù∏Ìä∏ Í∏∞Ï§Ä ID
c0 identity list --endpoints

# ÏóîÎìúÌè¨Ïù∏Ìä∏ ÏÑ§Ï†ï ÌôïÏù∏ Î∞è Î≥ÄÍ≤Ω
c0 endpoint config <ÏóîÌä∏Ìè¨Ïù∏Ìä∏ID>

# ÏóîÎìúÌè¨Ïù∏Ìä∏ ÏÉÅÏÑ∏ Ï†ïÎ≥¥ ÌôïÏù∏
c0 endpoint get <ÏóîÌä∏Ìè¨Ïù∏Ìä∏ID>

# ÏóîÎìúÌè¨Ïù∏Ìä∏ Î°úÍ∑∏ ÌôïÏù∏
c0 endpoint log <ÏóîÌä∏Ìè¨Ïù∏Ìä∏ID>

# Show bpf filesystem mount details
c0 bpf fs show

# bfp ÎßàÏö¥Ìä∏ Ìè¥Îçî ÌôïÏù∏
tree /sys/fs/bpf


# Get list of loadbalancer services
c0 service list
c1 service list
c2 service list

## Or you can get the loadbalancer information using bpf list
c0 bpf lb list
c1 bpf lb list
c2 bpf lb list

## List reverse NAT entries
c1 bpf lb list --revnat
c2 bpf lb list --revnat


# List connection tracking entries
c0 bpf ct list global
c1 bpf ct list global
c2 bpf ct list global

# Flush connection tracking entries
c0 bpf ct flush
c1 bpf ct flush
c2 bpf ct flush


# List all NAT mapping entries
c0 bpf nat list
c1 bpf nat list
c2 bpf nat list

# Flush all NAT mapping entries
c0 bpf nat flush
c1 bpf nat flush
c2 bpf nat flush

# Manage the IPCache mappings for IP/CIDR <-> Identity
c0 bpf ipcache list# Display cgroup metadata maintained by Cilium
c0 cgroups list
c1 cgroups list
c2 cgroups list


# List all open BPF maps
c0 map list
c1 map list --verbose
c2 map list --verbose

c1 map events cilium_lb4_services_v2
c1 map events cilium_lb4_reverse_nat
c1 map events cilium_lxc
c1 map events cilium_ipcache


# List all metrics
c1 metrics list


# List contents of a policy BPF map : Dump all policy maps
c0 bpf policy get --all
c1 bpf policy get --all -n
c2 bpf policy get --all -n


# Dump StateDB contents as JSON
c0 statedb dump


#
c0 shell -- db/show devices
c1 shell -- db/show devices
c2 shell -- db/show devices>)
```

- Getting Started with the Star Wars Demo & Hubble/UI
  - Deploy the Demo Application
![[Pasted image 20250725164406.png]]
- Ïä§ÌÉÄÏõåÏ¶àÏóêÏÑú ÏòÅÍ∞êÏùÑ Î∞õÏùÄ ÏòàÏ†úÏóêÏÑúÎäî Îç∞Ïä§Ïä§ÌÉÄ, ÌÉÄÏù¥ÌååÏù¥ÌÑ∞, ÏóëÏä§ÏúôÏùò ÏÑ∏ Í∞ÄÏßÄ ÎßàÏù¥ÌÅ¨Î°úÏÑúÎπÑÏä§ Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖòÏù¥ ÏûàÏäµÎãàÎã§.
- Îç∞Ïä§Ïä§ÌÉÄÎäî Ìè¨Ìä∏ 80ÏóêÏÑú HTTP ÏõπÏÑúÎπÑÏä§Î•º Ïã§ÌñâÌïòÎ©∞, Ïù¥ ÏÑúÎπÑÏä§Îäî Îëê Í∞úÏùò Ìè¨Îìú Î≥µÏ†úÎ≥∏Ïóê Í±∏Ï≥ê Îç∞Ïä§Ïä§ÌÉÄÏóê ÎåÄÌïú ÏöîÏ≤≠ÏùÑ Î°úÎìú Î∞∏Îü∞Ïã±ÌïòÎäî Kubernetes ÏÑúÎπÑÏä§Î°ú ÎÖ∏Ï∂úÎê©ÎãàÎã§.
- Îç∞Ïä§Ïä§ÌÉÄ ÏÑúÎπÑÏä§Îäî Ï†úÍµ≠Ïùò Ïö∞Ï£ºÏÑ†Ïóê Ï∞©Î•ô ÏÑúÎπÑÏä§Î•º Ï†úÍ≥µÌïòÏó¨ Ï∞©Î•ô Ìè¨Ìä∏Î•º ÏöîÏ≤≠Ìï† Ïàò ÏûàÎèÑÎ°ù Ìï©ÎãàÎã§.
- ÌÉÄÏù¥ÌååÏù¥ÌÑ∞ Ìè¨ÎìúÎäî ÏùºÎ∞òÏ†ÅÏù∏ Ï†úÍµ≠ ÏÑ†Î∞ïÏùò Ï∞©Î•ô ÏöîÏ≤≠ ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÑúÎπÑÏä§Î•º ÎÇòÌÉÄÎÇ¥Î©∞, ÏóëÏä§ÏúôÏùÄ ÎèôÎßπ ÏÑ†Î∞ïÏùò Ïú†ÏÇ¨Ìïú ÏÑúÎπÑÏä§Î•º ÎÇòÌÉÄÎÉÖÎãàÎã§.
- Îç∞Ïä§Ïä§ÌÉÄ Ï∞©Î•ô ÏÑúÎπÑÏä§Ïóê ÎåÄÌïú Ï†ëÍ∑º Ï†úÏñ¥Î•º ÏúÑÌïú Îã§ÏñëÌïú Î≥¥Ïïà Ï†ïÏ±ÖÏùÑ ÌÖåÏä§Ìä∏Ìï† Ïàò ÏûàÎèÑÎ°ù Ï°¥Ïû¨Ìï©ÎãàÎã§.
```
#
kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/http-sw-app.yaml
service/deathstar created
deployment.apps/deathstar created
pod/tiefighter created
pod/xwing created

# ÌååÎìú ÎùºÎ≤® labels ÌôïÏù∏
kubectl get pod --show-labels
NAME                        READY   STATUS    RESTARTS   AGE   LABELS
deathstar-8c4c77fb7-9klws   1/1     Running   0          29s   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=8c4c77fb7
deathstar-8c4c77fb7-kkwds   1/1     Running   0          29s   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=8c4c77fb7
tiefighter                  1/1     Running   0          29s   app.kubernetes.io/name=tiefighter,class=tiefighter,org=empire
xwing                       1/1     Running   0          29s   app.kubernetes.io/name=xwing,class=xwing,org=alliance

kubectl get deploy,svc,ep deathstar
NAME                        READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/deathstar   2/2     2            2           114s

NAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/deathstar   ClusterIP   10.96.154.223   <none>        80/TCP    114s

NAME                  ENDPOINTS                      AGE
endpoints/deathstar   172.20.1.34:80,172.20.2.1:80   114s

#
kubectl get ciliumendpoints.cilium.io -A
kubectl get ciliumidentities.cilium.io

# in a multi-node installation, only the ones running on the same node will be listed
kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- cilium endpoint list
c0 endpoint list
c1 endpoint list
c2 endpoint list # ÌòÑÏû¨ ingress/egress Ïóê Ï†ïÏ±Ö(Policy) ÏóÜÏùå! , Labels Ï†ïÎ≥¥ ÌôïÏù∏
ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])
...
1579       Disabled           Disabled          318        k8s:app.kubernetes.io/name=deathstar                                                172.20.2.1    ready   
                                                           k8s:class=deathstar                                                                                       
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default                                    
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                  
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                                           
                                                           k8s:io.kubernetes.pod.namespace=default                                                                   
                                                           k8s:org=empire   
```
- **Check Current Access**
    - Îç∞Ïä§Ïä§ÌÉÄ ÏÑúÎπÑÏä§Ïùò Í¥ÄÏ†êÏóêÏÑú Î≥¥Î©¥, org= empire ÎùºÎ≤®Ïù¥ Î∂ÄÏ∞©Îêú ÏÑ†Î∞ïÎßå Ïó∞Í≤∞ÌïòÏó¨ Ï∞©Î•ôÏùÑ ÏöîÏ≤≠Ìï† Ïàò ÏûàÏäµÎãàÎã§.
    - Ïö∞Î¶¨Îäî Í∑úÏπôÏùÑ ÏãúÌñâÌïòÏßÄ ÏïäÍ∏∞ ÎïåÎ¨∏Ïóê XwingÍ≥º ÌÉÄÏù¥ÌååÏù¥ÌÑ∞ Î™®Îëê Ï∞©Î•ôÏùÑ ÏöîÏ≤≠Ìï† Ïàò ÏûàÏäµÎãàÎã§. Ïù¥Î•º ÌÖåÏä§Ìä∏ÌïòÎ†§Î©¥ ÏïÑÎûò Î™ÖÎ†πÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
```
# ÏïÑÎûò Ï∂úÎ†•ÏóêÏÑú xwing ÏôÄ tiefighter Ïùò IDENTITY Î©îÎ™®
c1 endpoint list | grep -iE 'xwing|tiefighter|deathstar'
c2 endpoint list | grep -iE 'xwing|tiefighter|deathstar'
XWINGID=17141
TIEFIGHTERID=56716
DEATHSTARID=8113

# Î™®ÎãàÌÑ∞ÎßÅ Ï§ÄÎπÑ : ÌÑ∞ÎØ∏ÎÑê 3Í∞ú, Îã®Ï∂ïÌÇ§ ÏÑ§Ï†ï
## Í∞ÅÍ∞Å monitor ÌôïÏù∏
c0 monitor -v -v
c1 monitor -v -v
c2 monitor -v -v

# Î™®ÎãàÌÑ∞ÎßÅ Ï§ÄÎπÑ : ÌÑ∞ÎØ∏ÎÑê 1Í∞ú
hubble observe -f

XWINGID=50633
TIEFIGHTERID=19274
DEATHSTARID=318

hubble observe -f --from-identity $XWINGID
hubble observe -f --protocol udp --from-identity $XWINGID
hubble observe -f --protocol tcp --from-identity $XWINGID

hubble observe -f --protocol tcp --from-identity $DEATHSTARID


# Ìò∏Ï∂ú ÏãúÎèÑ 1
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
while true; do kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing ; sleep 5 ; done



# Ìò∏Ï∂ú ÏãúÎèÑ 2
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing
while true; do kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing ; sleep 5 ; done

## Î™®ÎãàÌÑ∞ÎßÅ
hubble observe -f --protocol tcp --from-identity $TIEFIGHTERID
hubble observe -f --protocol tcp --from-identity $DEATHSTARID

```
- Apply an L3/L4 Policy
![[Pasted image 20250725171932.png]]
- CiliumÏùÑ ÏÇ¨Ïö©Ìï† Îïå Î≥¥Ïïà Ï†ïÏ±ÖÏùÑ Ï†ïÏùòÌï† Îïå ÏóîÎìúÌè¨Ïù∏Ìä∏ IP Ï£ºÏÜåÎäî Ï§ëÏöîÌïòÏßÄ ÏïäÏäµÎãàÎã§. ÎåÄÏã† **Ìè¨ÎìúÏóê Ìï†ÎãπÎêú Î†àÏù¥Î∏î**ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ **Î≥¥Ïïà Ï†ïÏ±ÖÏùÑ Ï†ïÏùò**Ìï† Ïàò ÏûàÏäµÎãàÎã§. Ï†ïÏ±ÖÏùÄ ÌÅ¥Îü¨Ïä§ÌÑ∞ ÎÇ¥ÏóêÏÑú Ïã§Ìñâ Ï§ëÏù¥Í±∞ÎÇò Ïã§Ìñâ Ï§ëÏù∏ ÏúÑÏπòÏóê Í¥ÄÍ≥ÑÏóÜÏù¥ Î†àÏù¥Î∏îÏùÑ Í∏∞Î∞òÏúºÎ°ú Ïò¨Î∞îÎ•∏ Ìè¨ÎìúÏóê Ï†ÅÏö©Îê©ÎãàÎã§.
- **Îç∞Ïä§Ïä§ÌÉÄ Ï∞©Î•ô ÏöîÏ≤≠**ÏùÑ ÎùºÎ≤®Ïù¥ ÏûàÎäî ÏÑ†Î∞ï(org=empire)ÏúºÎ°úÎßå **Ï†úÌïú**ÌïòÎäî **Í∏∞Î≥∏ Ï†ïÏ±Ö**Î∂ÄÌÑ∞ ÏãúÏûëÌïòÍ≤†ÏäµÎãàÎã§. Ïù¥Î†áÍ≤å ÌïòÎ©¥ org=empire ÎùºÎ≤®Ïù¥ ÏóÜÎäî ÏÑ†Î∞ïÏùÄ Îç∞Ïä§Ïä§ÌÉÄ ÏÑúÎπÑÏä§ÏôÄ Ïó∞Í≤∞Ï°∞Ï∞® Ìï† Ïàò ÏóÜÏäµÎãàÎã§. Ïù¥ Ï†ïÏ±ÖÏùÄ IP ÌîÑÎ°úÌÜ†ÏΩú(ÎÑ§Ìä∏ÏõåÌÅ¨ Í≥ÑÏ∏µ 3)Í≥º TCP ÌîÑÎ°úÌÜ†ÏΩú(ÎÑ§Ìä∏ÏõåÌÅ¨ Í≥ÑÏ∏µ 4)ÏóêÎßå Ï†ÅÏö©ÎêòÎäî Í∞ÑÎã®Ìïú Ï†ïÏ±ÖÏù¥ÎØÄÎ°ú ÌùîÌûà **L3/L4 ÎÑ§Ìä∏ÏõåÌÅ¨ Î≥¥Ïïà Ï†ïÏ±Ö**Ïù¥ÎùºÍ≥† Ìï©ÎãàÎã§.
- Ï∞∏Í≥†: Ïã§Î¶¨ÏõÄÏùÄ **ÏÉÅÌÉúÎ≥Ñ Ïó∞Í≤∞ Ï∂îÏ†Å**ÏùÑ ÏàòÌñâÌï©ÎãàÎã§. Ïù¥Îäî Ï†ïÏ±ÖÏù¥ ÌîÑÎ°†Ìä∏ÏóîÎìúÍ∞Ä Î∞±ÏóîÎìúÏóê ÎèÑÎã¨Ìï† Ïàò ÏûàÎèÑÎ°ù ÌóàÏö©ÌïòÎ©¥, ÎèôÏùºÌïú TCP/UDP Ïó∞Í≤∞ ÎÇ¥ÏóêÏÑú Î∞±ÏóîÎìú ÏùëÎãµÏùò ÏùºÎ∂ÄÏù∏ Î™®Îì† **ÌïÑÏàò ÏùëÎãµ Ìå®ÌÇ∑Ïù¥ ÏûêÎèô**ÏúºÎ°ú ÌîÑÎ°†Ìä∏ÏóîÎìúÏóê ÎèÑÎã¨ÌïòÎèÑÎ°ù **ÌóàÏö©**ÌïúÎã§Îäî Í≤ÉÏùÑ ÏùòÎØ∏Ìï©ÎãàÎã§. _**‚Üí Î¶¨ÌÑ¥ Ìå®ÌÇ∑ ÏûêÎèô ÌóàÏö©!**_
```
# CiliumNetworkPolicy
## CiliumNetworkPolicysÎäî "endpointSelector"Î•º ÏÇ¨Ïö©ÌïòÏó¨ Ìåü Î†àÏù¥Î∏îÏóêÏÑú Ï†ïÏ±ÖÏù¥ Ï†ÅÏö©ÎêòÎäî ÏÜåÏä§ÏôÄ Î™©Ï†ÅÏßÄÎ•º ÏãùÎ≥ÑÌï©ÎãàÎã§. 
## ÏïÑÎûò Ï†ïÏ±ÖÏùÄ TCP Ìè¨Ìä∏ 80ÏóêÏÑú Î†àÏù¥Î∏î(org=empire)Ïù¥ ÏûàÎäî Î™®Îì† ÌåüÏóêÏÑú Î†àÏù¥Î∏î(org=empire, class=deathstar)Ïù¥ ÏûàÎäî Îç∞Ïä§Ïä§ÌÉÄ ÌåüÏúºÎ°ú Ï†ÑÏÜ°ÎêòÎäî Ìä∏ÎûòÌîΩÏùÑ ÌôîÏù¥Ìä∏Î¶¨Ïä§Ìä∏Î°ú ÏûëÏÑ±Ìï©ÎãàÎã§.
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "L3-L4 policy to restrict deathstar access to empire ships only"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - fromEndpoints:
    - matchLabels:
        org: empire
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP

kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/sw_l3_l4_policy.yaml
kubectl get cnp
kubectl get cnp -o json | jq

# Î™®ÎãàÌÑ∞ÎßÅ
hubble observe -f --type drop

# Ìò∏Ï∂ú ÏãúÎèÑ 1 
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing --connect-timeout 2


# Î™®ÎãàÌÑ∞ÎßÅ 
hubble observe -f --protocol tcp --from-identity $DEATHSTARID

# Ìò∏Ï∂ú ÏãúÎèÑ 2
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing

```
- Inspecting the Policy
```
# deathstar Ïóê ingress Ïóê policy ÌôúÏÑ±Ìôî ÌôïÏù∏
c0 endpoint list
c1 endpoint list
c2 endpoint list
ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value]) 
...
1579       Enabled            Disabled          318        k8s:app.kubernetes.io/name=deathstar                                                172.20.2.1    ready   
                                                           k8s:class=deathstar                                                                                       
                                                           k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default                                    
                                                           k8s:io.cilium.k8s.policy.cluster=default                                                                  
                                                           k8s:io.cilium.k8s.policy.serviceaccount=default                                                           
                                                           k8s:io.kubernetes.pod.namespace=default                                                                   
                                                           k8s:org=empire  
                                                           
#
kc describe cnp rule1

```

- Life of a Packet : L7 ÎèôÏûë Ï≤òÎ¶¨Îäî cilium-envoy Îç∞Î™¨ÏÖãÏù¥ Îã¥Îãπ
![[Pasted image 20250725172102.png]]
```
#
kubectl get ds -n kube-system
NAME           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
cilium         3         3         3       3            3           kubernetes.io/os=linux   3h38m
cilium-envoy   3         3         3       3            3           kubernetes.io/os=linux   3h38m

kubectl get pod -n kube-system -l k8s-app=cilium-envoy -owide
NAME                 READY   STATUS    RESTARTS   AGE     IP               NODE      NOMINATED NODE   READINESS GATES
cilium-envoy-8427n   1/1     Running   0          3h38m   192.168.10.100   k8s-ctr   <none>           <none>
cilium-envoy-8rzsb   1/1     Running   0          3h36m   192.168.10.101   k8s-w1    <none>           <none>
cilium-envoy-vkqw6   1/1     Running   0          3h35m   192.168.10.102   k8s-w2    <none>           <none>

#
kc describe ds -n kube-system cilium-envoy
...
    Mounts:
      /sys/fs/bpf from bpf-maps (rw)
      /var/run/cilium/envoy/ from envoy-config (ro)
      /var/run/cilium/envoy/artifacts from envoy-artifacts (ro)
      /var/run/cilium/envoy/sockets from envoy-sockets (rw
   ...
   envoy-config:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      cilium-envoy-config
    Optional:  false
...


kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- ss -xnp | grep -i -envoy
u_str ESTAB 0      0                                                  /var/run/cilium/envoy/sockets/xds.sock 32644            * 32610 users:(("cilium-agent",pid=1,fd=64))
u_str ESTAB 0      0                                                /var/run/cilium/envoy/sockets/admin.sock 29697            * 29345
u_str ESTAB 0      0                                                /var/run/cilium/envoy/sockets/admin.sock 29340            * 28672

kc describe cm -n kube-system cilium-envoy-config
...
Data
====
bootstrap-config.json:
----
{"admin":{"address":{"pipe":{"path":"/var/run/cilium/envoy/sockets/admin.sock"}}}...
...

```
- Apply and Test HTTP-aware L7 Policy
![[Pasted image 20250725172147.png]]

- ÏúÑÏùò Í∞ÑÎã®Ìïú ÏãúÎÇòÎ¶¨Ïò§ÏóêÏÑúÎäî tiefighter / xwingÏóêÍ≤å Îç∞Ïä§Ïä§ÌÉÄ APIÏóê ÎåÄÌïú Ï†ÑÏ≤¥ Ïï°ÏÑ∏Ïä§ Í∂åÌïúÏùÑ Î∂ÄÏó¨ÌïòÍ±∞ÎÇò ÏïÑÏòà Ïï°ÏÑ∏Ïä§ Í∂åÌïúÏùÑ Î∂ÄÏó¨ÌïòÏßÄ ÏïäÎäî Í≤ÉÏúºÎ°ú Ï∂©Î∂ÑÌñàÏäµÎãàÎã§. Í∑∏Îü¨ÎÇò ÎßàÏù¥ÌÅ¨Î°úÏÑúÎπÑÏä§ Í∞ÑÏóê Í∞ÄÏû• Í∞ïÎ†•Ìïú Î≥¥Ïïà(Ï¶â, ÏµúÏÜå Í∂åÌïú Í≤©Î¶¨Î•º Í∞ïÏ†úÌïòÎäî Í≤É)ÏùÑ Ï†úÍ≥µÌïòÍ∏∞ ÏúÑÌï¥ÏÑúÎäî Îç∞Ïä§Ïä§ÌÉÄ APIÎ•º Ìò∏Ï∂úÌïòÎäî Í∞Å ÏÑúÎπÑÏä§Í∞Ä **Ìï©Î≤ïÏ†ÅÏù∏ Ïö¥ÏòÅÏóê ÌïÑÏöîÌïú HTTP ÏöîÏ≤≠ ÏÑ∏Ìä∏Îßå ÏàòÌñâ**ÌïòÎèÑÎ°ù Ï†úÌïúÌï¥Ïïº Ìï©ÎãàÎã§.
- ÏòàÎ•º Îì§Ïñ¥, Îç∞Ïä§Ïä§ÌÉÄ ÏÑúÎπÑÏä§Í∞Ä ÏûÑÏùòÏùò Ï†úÍµ≠ ÏÑ†Î∞ïÏù¥ **Ìò∏Ï∂úÌï¥ÏÑúÎäî Ïïà ÎêòÎäî ÏùºÎ∂Ä Ïú†ÏßÄÎ≥¥Ïàò APIÎ•º ÎÖ∏Ï∂ú**ÌïúÎã§Í≥† Í∞ÄÏ†ïÌï¥ Î≥¥Í≤†ÏäµÎãàÎã§.
```
# Î™®ÎãàÌÑ∞ÎßÅ >> Layer3/4 ÏóêÏÑúÎäî Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò ÏÉÅÌÉúÎ•º ÌôïÏù∏ Ìï† Ïàò ÏóÜÏùå!
hubble observe -f --protocol tcp --from-identity $DEATHSTARID

# Ìò∏Ï∂úÌï¥ÏÑúÎäî Ïïà ÎêòÎäî ÏùºÎ∂Ä Ïú†ÏßÄÎ≥¥Ïàò APIÎ•º ÎÖ∏Ï∂ú
kubectl exec tiefighter -- curl -s -XPUT deathstar.default.svc.cluster.local/v1/exhaust-port

```

- L7 Policy with Cilium and Kubernetes
  - CiliumÏùÄ HTTP Í≥ÑÏ∏µ(Ï¶â, L7) Ï†ïÏ±ÖÏùÑ Ï†ÅÏö©ÌïòÏó¨ ÌÉÄÏù¥ÌååÏù¥ÌÑ∞Í∞Ä ÎèÑÎã¨Ìï† Ïàò ÏûàÎäî URLÏùÑ Ï†úÌïúÌï† Ïàò ÏûàÏäµÎãàÎã§. Îã§ÏùåÏùÄ ÌÉÄÏù¥ÌååÏù¥ÌÑ∞Î•º POST /v1/ÏöîÏ≤≠-ÎûúÎî© API Ìò∏Ï∂úÎßå ÏàòÌñâÌïòÎèÑÎ°ù Ï†úÌïúÌïòÍ≥† Îã§Î•∏ Î™®Îì† Ìò∏Ï∂ú(PUT /v1/Î∞∞Í∏∞Ìè¨Ìä∏ Ìè¨Ìï®)ÏùÄ ÌóàÏö©ÌïòÏßÄ ÏïäÎäî Ï†ïÏ±Ö ÌååÏùºÏùò ÏòàÏûÖÎãàÎã§.
```
# Í∏∞Ï°¥ rule1 Ï†ïÏ±ÖÏùÑ ÏóÖÎç∞Ïù¥Ìä∏ Ìï¥ÏÑú ÏÇ¨Ïö©
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "L7 policy to restrict access to specific HTTP call"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - fromEndpoints:
    - matchLabels:
        org: empire
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP
      rules:
        http:
        - method: "POST"
          path: "/v1/request-landing"

# Update the existing rule to apply L7-aware policy to protect deathstar using:
kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/sw_l3_l4_l7_policy.yaml
kubectl get cnp
kc describe cnp
c0 policy get


# Î™®ÎãàÌÑ∞ÎßÅ : ÌååÎìú Ïù¥Î¶Ñ ÏßÄÏ†ï
hubble observe -f --pod deathstar --protocol http
Jul 20 01:28:02.184: default/tiefighter:59020 (ID:19274) -> default/deathstar-8c4c77fb7-9klws:80 (ID:318) http-request FORWARDED (HTTP/1.1 POST http://deathstar.default.svc.cluster.local/v1/request-landing)
Jul 20 01:28:02.190: default/tiefighter:59020 (ID:19274) <- default/deathstar-8c4c77fb7-9klws:80 (ID:318) http-response FORWARDED (HTTP/1.1 200 6ms (POST http://deathstar.default.svc.cluster.local/v1/request-landing))

# We can now re-run the same test as above, but we will see a different outcome
kubectl exec tiefighter -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing

```

```
# Î™®ÎãàÌÑ∞ÎßÅ : ÌååÎìú Ïù¥Î¶Ñ ÏßÄÏ†ï
hubble observe -f --pod deathstar --verdict DROPPED
Jul 20 01:31:21.248: default/tiefighter:44734 (ID:19274) -> default/deathstar-8c4c77fb7-9klws:80 (ID:318) http-request DROPPED (HTTP/1.1 PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port)

ÌòπÏùÄ
c1 monitor -v --type l7
<- Request http from 3845 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) to 871 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 19274->318, verdict Denied PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port => 0
<- Response http to 3845 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) from 871 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 318->19274, verdict Forwarded PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port => 403
c2 monitor -v --type l7


# We can now re-run the same test as above, but we will see a different outcome
kubectl exec tiefighter -- curl -s -XPUT deathstar.default.svc.cluster.local/v1/exhaust-port
Access denied



# Î™®ÎãàÌÑ∞ÎßÅ : ÌååÎìú Ïù¥Î¶Ñ ÏßÄÏ†ï
hubble observe -f --pod xwing

# Ìò∏Ï∂ú ÏãúÎèÑ : ÏúÑÏôÄ ÏïÑÎûò Ïã§Ìñâ Ï¢ÖÎ£åÏùò Ï∞®Ïù¥Ï†êÏùÑ Ïù¥Ìï¥Ìï¥Î≥¥Ïûê!
kubectl exec xwing -- curl -s -XPOST deathstar.default.svc.cluster.local/v1/request-landing --connect-timeout 2

```
- Îã§Ïùå Ïã§ÏäµÏùÑ ÏúÑÌï¥ Î¶¨ÏÜåÏä§ ÏÇ≠Ï†ú
```
# Îã§Ïùå Ïã§ÏäµÏùÑ ÏúÑÌï¥ Î¶¨ÏÜåÏä§ ÏÇ≠Ï†ú
kubectl delete -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/http-sw-app.yaml
kubectl delete cnp rule1

# ÏÇ≠Ï†ú ÌôïÏù∏
kubectl get cnp

```

- Configuring Hubble exporter : ÌùêÎ¶Ñ Î°úÍ∑∏
  - Hubble ExporterÎäî ÎÇòÏ§ëÏóê ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎèÑÎ°ù **Hubble flows Î°úÍ∑∏Î•º ÌååÏùº**Ïóê Ï†ÄÏû•Ìï† Ïàò ÏûàÎäî cilium-agentÏùò Í∏∞Îä•ÏûÖÎãàÎã§.
  - Hubble ExporterÎäî file rotation, size limits, filters, field masksÎ•º ÏßÄÏõêÌï©ÎãàÎã§.
  - **Hubble Exporter ÏÑ§Ï†ï** ‚Üê Hubble ÏÑ§Ïπò Îïå Í∞ôÏù¥ Ï†ÅÏö©ÎêòÏñ¥ ÏûàÏùå
```
# ÏÑ§Ï†ï : ÏïÑÎûò ÏÑ§Ï†ïÌï† ÌïÑÏöî ÏóÜÏùå
helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
   --set hubble.enabled=true \
   --set hubble.export.static.enabled=true \
   --set hubble.export.static.filePath=/var/run/cilium/hubble/events.log

kubectl -n kube-system rollout status ds/cilium


# ÌôïÏù∏
kubectl get cm -n kube-system cilium-config -o json | grep hubble-export
cilium config view | grep hubble-export
hubble-export-allowlist                           
hubble-export-denylist                            
hubble-export-fieldmask                           
hubble-export-file-max-backups   # number of rotated Hubble export files to keep. (default 5)
hubble-export-file-max-size-mb   # size in MB at which to rotate the Hubble export file. (default 10)
hubble-export-file-path          # file path of target log file. (default /var/run/cilium/hubble/events.log)

# Verify that flow logs are stored in target files
kubectl -n kube-system exec ds/cilium -- tail -f /var/run/cilium/hubble/events.log
kubectl -n kube-system exec ds/cilium -- sh -c 'tail -f /var/run/cilium/hubble/events.log' | jq

```

- Performance tuning
  - Configuration options impacting performance of¬†**Hubble exporter**¬†include:
    - `hubble.export.static.allowList`: specify an **allowlist** as JSON encoded FlowFilters to Hubble exporter.
    - `hubble.export.static.denyList`: specify a **denylist** as JSON encoded FlowFilters to Hubble exporter.
    - `hubble.export.static.fieldMask`: specify a **list** of **fields** to use for field masking in Hubble exporter.
  - Filters & Field mas
    - Field mask is a list of field names from the¬†[flow proto](https://github.com/cilium/cilium/blob/main/api/v1/flow/flow.proto)¬†definition.
```
# You can use hubble CLI to generated required filters (see Specifying Raw Flow Filters for more examples).
# For example, to filter flows with verdict DENIED or ERROR, run:
hubble observe --verdict DROPPED --verdict ERROR --print-raw-filters
allowlist:
- '{"verdict":["DROPPED","ERROR"]}'


# To keep all information except pod labels:
hubble-export-fieldmask: time source.identity source.namespace source.pod_name destination.identity destination.namespace destination.pod_name source_service destination_service l4 IP ethernet l7 Type node_name is_reply event_type verdict Summary

# To keep only timestamp, verdict, ports, IP addresses, node name, pod name, and namespace:
hubble-export-fieldmask: time source.namespace source.pod_name destination.namespace destination.pod_name l4 IP node_name is_reply verdict


# ÏÑ§Ï†ï Î∞©Ïïà 1 : Then paste the output to hubble-export-allowlist in cilium-config Config Map:
kubectl -n kube-system patch cm cilium-config --patch-file=/dev/stdin <<-EOF
data:
  hubble-export-allowlist: '{"verdict":["DROPPED","ERROR"]}'
  hubble-export-denylist: '{"source_pod":["kube-system/"]},{"destination_pod":["kube-system/"]}'
EOF

# ÏÑ§Ï†ï Î∞©Ïïà 2 : helm ÏóÖÍ∑∏Î†àÏù¥Îìú
helm upgrade cilium cilium/cilium --version 1.17.6 \
   --set hubble.enabled=true \
   --set hubble.export.static.enabled=true \
   --set hubble.export.static.filePath=/var/run/cilium/hubble/events.log \
   --set hubble.export.static.allowList[0]='{"verdict":["DROPPED","ERROR"]}'
   --set hubble.export.static.denyList[0]='{"source_pod":["kube-system/"]}' \
   --set hubble.export.static.denyList[1]='{"destination_pod":["kube-system/"]}' \
   --set "hubble.export.static.fieldMask={time,source.namespace,source.pod_name,destination.namespace,destination.pod_name,l4,IP,node_name,is_reply,verdict,drop_reason_desc}"


# ÌôïÏù∏
cilium config view | grep hubble-export
hubble-export-allowlist                           {"verdict":["DENIED","ERROR"]}
...

kubectl -n kube-system exec ds/cilium -- tail -f /var/run/cilium/hubble/events.log
{"flow":{"time":"2023-08-21T12:12:13.517394084Z","verdict":"DROPPED","IP":{"source":"fe80::64d8:8aff:fe72:fc14","destination":"ff02::2","ipVersion":"IPv6"},"l4":{"ICMPv6":{"type":133}},"source":{},"destination":{},"node_name":"kind-kind/kind-worker","drop_reason_desc":"INVALID_SOURCE_IP"},"node_name":"kind-kind/kind-worker","time":"2023-08-21T12:12:13.517394084Z"}
{"flow":{"time":"2023-08-21T12:12:18.510175415Z","verdict":"DROPPED","IP":{"source":"10.244.1.60","destination":"10.244.1.5","ipVersion":"IPv4"},"l4":{"TCP":{"source_port":44916,"destination_port":80,"flags":{"SYN":true}}},"source":{"namespace":"default","pod_name":"xwing"},"destination":{"namespace":"default","pod_name":"deathstar-7848d6c4d5-th9v2"},"node_name":"kind-kind/kind-worker","drop_reason_desc":"POLICY_DENIED"},"node_name":"kind-kind/kind-worker","time":"2023-08-21T12:12:18.510175415Z"}

```

- **Dynamic exporter configuration - [Docs](https://docs.cilium.io/en/stable/observability/hubble/configuration/export/#dynamic-exporter-configuration)
    - **Standard hubble exporter configuration**ÏùÄ only one set of filters ÌóàÏö©ÌïòÎ©∞ Íµ¨ÏÑ±ÏùÑ Î≥ÄÍ≤ΩÌïòÎ†§Î©¥ only one set of filtersÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.
    - **Dynamic flow logs**Î•º ÏÇ¨Ïö©ÌïòÎ©¥ Ïó¨Îü¨ ÌïÑÌÑ∞Î•º ÎèôÏãúÏóê Íµ¨ÏÑ±ÌïòÍ≥† Ï∂úÎ†•ÏùÑ Î≥ÑÎèÑÏùò ÌååÏùºÏóê Ï†ÄÏû•Ìï† Ïàò ÏûàÏäµÎãàÎã§. ÎòêÌïú Î≥ÄÍ≤ΩÎêú Íµ¨ÏÑ±ÏùÑ Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌï¥ **Ïã§Î•® Ìè¨Îìú Ïû¨ÏãúÏûëÏù¥ ÌïÑÏöîÌïòÏßÄ ÏïäÏäµ**ÎãàÎã§.
    - **Dynamic Hubble Exporter**Îäî Config Map ÏÜçÏÑ±ÏúºÎ°ú ÌôúÏÑ±ÌôîÎê©ÎãàÎã§. ÌååÏùº Í≤ΩÎ°ú Í∞íÏùÑ hubble-flowlogs-config-pathÎ°ú ÏÑ§Ï†ïÌï† ÎïåÍπåÏßÄ ÎπÑÌôúÏÑ±ÌôîÎê©ÎãàÎã§.
```
# ÏÑ§Ï†ï 
helm upgrade cilium cilium/cilium --namespace kube-system --reuse-values \
   --set hubble.enabled=true \
   --set hubble.export.static.enabled=false \
   --set hubble.export.dynamic.enabled=true

kubectl -n kube-system rollout status ds/cilium


# Ìè¨ÎìúÎ•º Ïû¨ÏãúÏûëÌï† ÌïÑÏöî ÏóÜÏù¥ ÌùêÎ¶Ñ Î°úÍ∑∏ ÏÑ§Ï†ïÏùÑ Î≥ÄÍ≤ΩÌï† Ïàò ÏûàÏäµÎãàÎã§(Íµ¨ÏÑ± Îßµ Ï†ÑÌåå ÏßÄÏó∞ÏúºÎ°ú Ïù∏Ìï¥ Î≥ÄÍ≤Ω ÏÇ¨Ìï≠ÏùÑ 60Ï¥à Ïù¥ÎÇ¥Ïóê Î∞òÏòÅÌï¥Ïïº Ìï®):
helm upgrade cilium cilium/cilium --version 1.17.6 \
   --set hubble.enabled=true \
   --set hubble.export.dynamic.enabled=true \
   --set hubble.export.dynamic.config.content[0].name=system \
   --set hubble.export.dynamic.config.content[0].filePath=/var/run/cilium/hubble/events-system.log \
   --set hubble.export.dynamic.config.content[0].includeFilters[0].source_pod[0]='kube_system/' \
   --set hubble.export.dynamic.config.content[0].includeFilters[1].destination_pod[0]='kube_system/'
```
- Dynamic flow logs can be configured with end property which means that it will automatically stop logging after specified date time. It supports the same field masking and filtering as static hubble exporter.
- For max output file size and backup files dynamic exporter reuses the same settings as static one: `hubble.export.fileMaxSizeMb` and `hubble.export.fileMaxBackups`

#### 2. Running Prometheus & Grafana
- **ÏÉòÌîå Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î∞∞Ìè¨ Î∞è ÌôïÏù∏**
    - ÏÉòÌîå Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î∞∞Ìè¨
```
# ÏÉòÌîå Ïï†ÌîåÎ¶¨ÏºÄÏù¥ÏÖò Î∞∞Ìè¨
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
EOF


# k8s-ctr ÎÖ∏ÎìúÏóê curl-pod ÌååÎìú Î∞∞Ìè¨
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
EOF
```
- ÌôïÏù∏
```
# Î∞∞Ìè¨ ÌôïÏù∏
kubectl get deploy,svc,ep webpod -owide
kubectl get endpointslices -l app=webpod
kubectl get ciliumendpoints
kubectl exec -it -n kube-system ds/cilium -c cilium-agent -- cilium-dbg endpoint list

# ÌÜµÏã† ÌôïÏù∏
kubectl exec -it curl-pod -- curl webpod | grep Hostname
kubectl exec -it curl-pod -- sh -c 'while true; do curl -s webpod | grep Hostname; sleep 1; done'

```

- **Install Prometheus & Grafana - [Docs](https://docs.cilium.io/en/stable/observability/grafana/)**
    - This is an example deployment that includes Prometheus and Grafana in a **single deployment**. - [Youtube](https://www.youtube.com/watch?v=DdWksYq5Pv4)
        - **Grafana**: A visualization dashboard with **Cilium Dashboard pre-loaded.**
        - **Prometheus**: a time series database and monitoring system.
        - This example deployment of Prometheus and Grafana will **automatically scrape** the **Cilium** and **Hubble metrics**.
```
#
kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes/addons/prometheus/monitoring-example.yaml
configmap/grafana-config created
configmap/grafana-cilium-dashboard created
configmap/grafana-cilium-operator-dashboard created
configmap/grafana-hubble-dashboard created
configmap/grafana-hubble-l7-http-metrics-by-workload created
configmap/prometheus created

#
kubectl get deploy,pod,svc,ep -n cilium-monitoring
kubectl get cm -n cilium-monitoring
NAME                                         DATA   AGE
grafana-cilium-dashboard                     1      113s
grafana-cilium-operator-dashboard            1      113s
grafana-config                               3      113s
grafana-hubble-dashboard                     1      113s
grafana-hubble-l7-http-metrics-by-workload   1      113s
prometheus                                   1      113s

# ÌîÑÎ°úÎ©îÌÖåÏö∞Ïä§ ÏÑúÎ≤Ñ ÏÑ§Ï†ï
kc describe cm -n cilium-monitoring prometheus

# Í∑∏ÎùºÌååÎÇò ÏÑúÎ≤Ñ ÏÑ§Ï†ï
kc describe cm -n cilium-monitoring grafana-config

# Í∑∏ÌååÎùºÎÇò ÎåÄÏãúÎ≥¥ÎìúÎì§ Ï£ºÏûÖÏùÑ ÏúÑÌïú ÏÑ§Ï†ï
kc describe cm -n cilium-monitoring grafana-cilium-dashboard
kc describe cm -n cilium-monitoring grafana-hubble-dashboard
...
```

- **Deploy Cilium and Hubble with metrics enabled - [Docs](https://docs.cilium.io/en/stable/observability/grafana/#deploy-cilium-and-hubble-with-metrics-enabled)**
    - Cilium, Hubble, and Cilium OperatorÎäî Í∏∞Î≥∏Ï†ÅÏúºÎ°ú Î©îÌä∏Î¶≠ÏùÑ ÎÖ∏Ï∂úÌïòÏßÄ ÏïäÏäµÎãàÎã§.
            - Ïù¥Îü¨Ìïú ÏÑúÎπÑÏä§Ïóê ÎåÄÌïú Î©îÌä∏Î¶≠ÏùÑ ÌôúÏÑ±ÌôîÌïòÎ©¥ Ïù¥Îü¨Ìïú Íµ¨ÏÑ± ÏöîÏÜåÍ∞Ä Ïã§Ìñâ Ï§ëÏù∏ ÌÅ¥Îü¨Ïä§ÌÑ∞Ïùò Î™®Îì† ÎÖ∏ÎìúÏóê Í∞ÅÍ∞Å **9962, 9965, 9963** Ìè¨Ìä∏Í∞Ä Ïó¥Î¶ΩÎãàÎã§.
           -  Cilium, Hubble, and Cilium OperatorÏùò Î©îÌä∏Î¶≠ÏùÄ Î™®Îëê Îã§Ïùå Ìó¨Î¶Ñ Í∞íÏúºÎ°ú ÏÑúÎ°ú ÎèÖÎ¶ΩÏ†ÅÏúºÎ°ú ÌôúÏÑ±ÌôîÌï† Ïàò ÏûàÏäµÎãàÎã§        
        - `prometheus.enabled=true`: Enables metrics for¬†`cilium-agent`.
        - `operator.prometheus.enabled=true`: Enables metrics for¬†`cilium-operator`.
        - `hubble.metrics.enabled`: Enables the provided list of Hubble metrics.
            - For Hubble metrics to work, Hubble itself needs to be enabled with¬†`hubble.enabled=true`.
            - See¬†[Hubble exported metrics](https://docs.cilium.io/en/stable/observability/metrics/#hubble-exported-metrics)¬†for the list of available Hubble metrics.
        
        _‚Üí Refer to¬†[Monitoring & Metrics](https://docs.cilium.io/en/stable/observability/metrics/#metrics)¬†for more details about the individual metrics._
    - Î©îÌä∏Î¶≠ ÎÖ∏Ï∂ú ÏÑ§Ï†ï ‚Üí Ïù¥ÎØ∏ ÎêòÏñ¥ ÏûàÏùå
```
# Ïù¥ÎØ∏ ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÏùå
helm install cilium cilium/cilium --version 1.17.6 \
   --namespace kube-system \
   --set prometheus.enabled=true \
   --set operator.prometheus.enabled=true \
   --set hubble.enabled=true \
   --set hubble.metrics.enableOpenMetrics=true \
   --set hubble.metrics.enabled="{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip\,source_namespace\,source_workload\,destination_ip\,destination_namespace\,destination_workload\,traffic_direction}"

# Ìò∏Ïä§Ìä∏Ïóê Ìè¨Ìä∏ Ï†ïÎ≥¥ ÌôïÏù∏
ss -tnlp | grep -E '9962|9963|9965'
LISTEN 0      4096                *:9963             *:*    users:(("cilium-operator",pid=1488,fd=7)) # cilium-opeator Î©îÌä∏Î¶≠        
LISTEN 0      4096                *:9962             *:*    users:(("cilium-agent",pid=1894,fd=7))    # cilium Î©îÌä∏Î¶≠  
LISTEN 0      4096                *:9965             *:*    users:(("cilium-agent",pid=1894,fd=40))   # hubble Î©îÌä∏Î¶≠

for i in w1 w2 ; do echo ">> node : k8s-$i <<"; sshpass -p 'vagrant' ssh vagrant@k8s-$i sudo ss -tnlp | grep -E '9962|9963|9965' ; echo; done

```

- hostPCÏóêÏÑú **Ï†ëÏÜçÏùÑ ÏúÑÌïú NodePort ÏÑ§Ï†ï** Î∞è ‚Äò**ÌîÑÎ°úÎ©îÌÖåÏö∞Ïä§ & Í∑∏ÎùºÌååÎÇò**‚Äô **Ïõπ Ï†ëÏÜç ÌôïÏù∏ & Í∞ÑÎã® ÏøºÎ¶¨Î¨∏ ÏïåÏïÑÎ≥¥Í∏∞!
  - hostPCÏóêÏÑú Ï†ëÏÜçÏùÑ ÏúÑÌïú NodePort ÏÑ§Ï†ï
```
#
kubectl get svc -n cilium-monitoring
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
grafana      ClusterIP   10.96.212.137   <none>        3000/TCP   6m36s
prometheus   ClusterIP   10.96.240.147   <none>        9090/TCP   6m36s

# NodePort ÏÑ§Ï†ï
kubectl patch svc -n cilium-monitoring prometheus -p '{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}'
kubectl patch svc -n cilium-monitoring grafana -p '{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}'

# ÌôïÏù∏
kubectl get svc -n cilium-monitoring
NAME         TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
grafana      NodePort   10.96.212.137   <none>        3000:30002/TCP   14m
prometheus   NodePort   10.96.240.147   <none>        9090:30001/TCP   14m

# Ï†ëÏÜç Ï£ºÏÜå ÌôïÏù∏
echo "http://192.168.10.100:30001"  # prometheus
echo "http://192.168.10.100:30002"  # grafana

```
